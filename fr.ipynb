{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install facenet-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import numpy as np\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def extract_face_encoding(image):\n",
    "    # Convert the image to RGB format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize the image to (160, 160) which is the input size of the FaceNet model\n",
    "    image = cv2.resize(image, (160, 160))\n",
    "    \n",
    "    # Convert the image to a PyTorch tensor and normalize its values\n",
    "    image = torch.from_numpy(image.transpose((2, 0, 1))).float().div(255).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Extract the facial features from the image using the FaceNet model\n",
    "    with torch.no_grad():\n",
    "        face_encoding = resnet(image)[0].cpu().numpy()\n",
    "    \n",
    "    return face_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_faces(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image using the Haar Cascade classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Return the coordinates of the detected faces\n",
    "    return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_face_encodings(face_encoding, known_face_encodings):\n",
    "    return [np.allclose(face_encoding, known_face_encoding, rtol=1e-2, atol=1e-2) for known_face_encoding in known_face_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(face_encoding, known_face_encodings):\n",
    "    temp = {}\n",
    "    for i in range(len(known_face_encodings)):\n",
    "        dist = np.linalg.norm(face_encoding-known_face_encodings[i])\n",
    "        temp[i]=dist\n",
    "    sort_dict = {k: v for k, v in sorted(temp.items(), key=lambda item: item[1])}\n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1833 3186   60   60]\n",
      " [1753 3209   62   62]\n",
      " [ 580 3220   62   62]\n",
      " [ 781 1164 1446 1446]\n",
      " [2003 3412   52   52]\n",
      " [1951 3329   74   74]\n",
      " [ 404 3450   59   59]\n",
      " [  80 2064   52   52]\n",
      " [2048 3101   56   56]]\n",
      "{0: 1.2250177, 1: 1.4717427, 2: 1.4206684, 3: 1.4838314, 4: 1.5253102, 5: 1.1196952, 6: 1.4408233, 7: 1.4833875, 8: 1.4946399, 9: 1.5348686}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(matches):\n\u001b[1;32m---> 53\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mmatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     54\u001b[0m     name \u001b[38;5;241m=\u001b[39m known_face_names[index]\n\u001b[0;32m     55\u001b[0m face_names\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the known faces and their names\n",
    "known_faces_dir = \"known_faces\"\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "for file in os.listdir(known_faces_dir):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "        image = cv2.imread(os.path.join(known_faces_dir, file))\n",
    "        face_encoding = extract_face_encoding(image)\n",
    "        known_face_encodings.append(face_encoding)\n",
    "        known_face_names.append(os.path.splitext(file)[0])\n",
    "\n",
    "# # Initialize the camera\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "unknown_faces_dir = \"unknown_faces\"\n",
    "file = \"abc.jpg\"\n",
    "frame = cv2.imread(os.path.join(unknown_faces_dir, file))\n",
    "# print(frame)\n",
    "# cv2.imshow('frame',frame)\n",
    "\n",
    "# Detect faces in the frame\n",
    "face_locations = detect_faces(frame)\n",
    "\n",
    "# Check if any faces are detected\n",
    "if face_locations is not None:\n",
    "    print(face_locations)\n",
    "    # Extract face encodings from the detected faces\n",
    "    \n",
    "    face_encodings = []\n",
    "    for face_location in face_locations:\n",
    "        face_image = frame[face_location[1]:face_location[1]+face_location[3], face_location[0]:face_location[0]+face_location[2]]\n",
    "#         cv2.imshow('face_image', face_image)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "#         cv2.waitKey(1)\n",
    "        face_encoding = extract_face_encoding(face_image)\n",
    "        face_encodings.append(face_encoding)\n",
    "\n",
    "    # Compare face encodings with known faces\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = compare(face_encoding, known_face_encodings)\n",
    "        print(matches)\n",
    "        name = \"Unknown\"\n",
    "        if any(matches):\n",
    "            index = matches.index(True)\n",
    "            name = known_face_names[index]\n",
    "        face_names.append(name)\n",
    "    print(face_names)\n",
    "    # Draw boxes and labels around the detected faces\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "else:\n",
    "    # Display message if no faces are detected\n",
    "    cv2.putText(frame, \"No faces detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "# Display the resulting frame\n",
    "# cv2.imshow('Facial Recognition', frame)\n",
    "# if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "#     break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-venv",
   "language": "python",
   "name": "new-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
