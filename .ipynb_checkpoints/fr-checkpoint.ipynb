{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in c:\\users\\khush\\anaconda3\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\khush\\anaconda3\\lib\\site-packages (from facenet-pytorch) (9.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\khush\\anaconda3\\lib\\site-packages (from facenet-pytorch) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\khush\\anaconda3\\lib\\site-packages (from facenet-pytorch) (1.21.5)\n",
      "Requirement already satisfied: torchvision in c:\\users\\khush\\anaconda3\\lib\\site-packages (from facenet-pytorch) (0.15.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests->facenet-pytorch) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests->facenet-pytorch) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests->facenet-pytorch) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from requests->facenet-pytorch) (1.26.9)\n",
      "Requirement already satisfied: torch==2.0.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torchvision->facenet-pytorch) (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (4.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0->torchvision->facenet-pytorch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0->torchvision->facenet-pytorch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def extract_face_encoding(image):\n",
    "    # Convert the image to RGB format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize the image to (160, 160) which is the input size of the FaceNet model\n",
    "    image = cv2.resize(image, (160, 160))\n",
    "    \n",
    "    # Convert the image to a PyTorch tensor and normalize its values\n",
    "    image = torch.from_numpy(image.transpose((2, 0, 1))).float().div(255).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Extract the facial features from the image using the FaceNet model\n",
    "    with torch.no_grad():\n",
    "        face_encoding = resnet(image)[0].cpu().numpy()\n",
    "    \n",
    "    return face_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_faces(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image using the Haar Cascade classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Return the coordinates of the detected faces\n",
    "    return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\college\\fr.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m face_location \u001b[39min\u001b[39;00m face_locations:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     face_image \u001b[39m=\u001b[39m frame[face_location[\u001b[39m0\u001b[39m]:face_location[\u001b[39m2\u001b[39m], face_location[\u001b[39m3\u001b[39m]:face_location[\u001b[39m1\u001b[39m]]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     face_encoding \u001b[39m=\u001b[39m extract_face_encoding(face_image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     face_encodings\u001b[39m.\u001b[39mappend(face_encoding)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Compare face encodings with known faces\u001b[39;00m\n",
      "\u001b[1;32md:\\college\\fr.ipynb Cell 5\u001b[0m in \u001b[0;36mextract_face_encoding\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_face_encoding\u001b[39m(image):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# Convert the image to RGB format\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(image, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Resize the image to (160, 160) which is the input size of the FaceNet model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/college/fr.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(image, (\u001b[39m160\u001b[39m, \u001b[39m160\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the known faces and their names\n",
    "known_faces_dir = \"known_faces\"\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "for file in os.listdir(known_faces_dir):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        image = cv2.imread(os.path.join(known_faces_dir, file))\n",
    "        face_encoding = extract_face_encoding(image)\n",
    "        known_face_encodings.append(face_encoding)\n",
    "        known_face_names.append(os.path.splitext(file)[0])\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    face_locations = detect_faces(frame)\n",
    "    \n",
    "    # Check if any faces are detected\n",
    "    if face_locations is not None:\n",
    "        # Extract face encodings from the detected faces\n",
    "        face_encodings = []\n",
    "        for face_location in face_locations:\n",
    "            face_image = frame[face_location[0]:face_location[2], face_location[3]:face_location[1]]\n",
    "            face_encoding = extract_face_encoding(face_image)\n",
    "            face_encodings.append(face_encoding)\n",
    "        \n",
    "        # Compare face encodings with known faces\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = compare_face_encodings(face_encoding, known_face_encodings)\n",
    "            name = \"Unknown\"\n",
    "            if any(matches):\n",
    "                index = matches.index(True)\n",
    "                name = known_face_names[index]\n",
    "            face_names.append(name)\n",
    "        \n",
    "        # Draw boxes and labels around the detected faces\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    else:\n",
    "        # Display message if no faces are detected\n",
    "        cv2.putText(frame, \"No faces detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Facial Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
