{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/urmidedhia/Synapse-Learning-Period/blob/NLP-week-3/Tasksentiment_rating_rnn_Urmi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qqkcLp4CmQzW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "wgydpm62zi04",
    "outputId": "bcddc3ee-0e21-4ef2-930d-934a9331f1ff"
   },
   "outputs": [],
   "source": [
    "'''Load the dataset into variable \"reviews\". You can truncate the dataset to keep a few hundred records if it's\n",
    "    taking too long to process/train. Keep in mind, bigger the dataset, higher the accuracy score!\n",
    "'''\n",
    "\n",
    "train = pd.read_csv('D:\\\\Coding\\\\Hackathons\\\\Codeshastra-checkmate\\\\train_set.csv')\n",
    "test = pd.read_csv('D:\\\\Coding\\\\Hackathons\\\\Codeshastra-checkmate\\\\test_set.csv')\n",
    "\n",
    "\n",
    "# reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Category 1: 'Risk' (Low performance, Low potential)\",\n",
       "       \"Category 2: 'Average performer' (Moderate performance, Low potential)\",\n",
       "       \"Category 3: 'Solid Performer' (High performance, Low potential)\",\n",
       "       \"Category 4: 'Inconsistent Player' (Low performance, Moderate potential)\",\n",
       "       \"Category 5: 'Core Player' (Moderate performance, Moderate potential)\",\n",
       "       \"Category 6: 'High Performer' (High performance, Moderate potential)\",\n",
       "       \"Category 7: 'Potential Gem' (Low performance, High potential)\",\n",
       "       \"Category 8: 'High Potential' (Moderate performance, High potential)\",\n",
       "       \"Category 9: 'Star' (High performance, High potential)\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nine_box_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rating(df):\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i, 2] = df.iloc[i, 2][9]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = encode_rating(train)\n",
    "train_df = train_df.drop(['id','person_name','adjusted','reviewed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'person_name', 'nine_box_category', 'feedback', 'updated',\n",
       "       'reviewed', 'label', 'performance_class', 'potential_class',\n",
       "       'feedback_clean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = encode_rating(test)\n",
    "test_df = test_df.drop(['id','person_name','updated','reviewed','label', 'performance_class', 'potential_class',\n",
    "       'feedback_clean'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "b9msiWLKzi05"
   },
   "outputs": [],
   "source": [
    "#Split the data into train and split\n",
    "# X = train_df[['feedback']] + test_df[['feedback']]\n",
    "# y = train_df[['nine_box_category']] + test_df[['nine_box_category']]\n",
    "# from sklearn.model_selection import train_test_split\n",
    "train_reviews, test_reviews, train_sentiment, test_sentiment = train_df[['feedback']],test_df[['feedback']],train_df[['nine_box_category']],test_df[['nine_box_category']]\n",
    "\n",
    "train_sentiment = pd.get_dummies(train_sentiment['nine_box_category']).values\n",
    "test_sentiment = pd.get_dummies(test_sentiment['nine_box_category']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "6wZfLm0qzi05",
    "outputId": "b95cb078-ee23-4fc5-f533-66b6a70f15b3"
   },
   "outputs": [],
   "source": [
    "# # convert the above train test datasets into a pandas dataframe. You shoud have 4 dataframes.\n",
    "# # Name them train_reviews, test_reviews, train_sentiment, test_sentiment.\n",
    "# # In train_sentiment and test_sentiment, convert \"positive\" to 1 and \"negative\" to 0\n",
    "# for df in [train_sentiment, test_sentiment]:\n",
    "#   df['sentiment'] = df['sentiment'].replace(['positive'],1)\n",
    "#   df['sentiment'] = df['sentiment'].replace(['negative'],0)\n",
    "\n",
    "# test_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_h7WaDXBzi06",
    "outputId": "12d864db-c11c-4c86-ae07-5ecc4ff7827d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 1) (225, 1)\n",
      "(878, 9) (225, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_reviews.shape,test_reviews.shape)\n",
    "print(train_sentiment.shape,test_sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jamie has delivered fantastic results. The wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jude has potential but needs coaching in sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonso has been an outstanding team member and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm always nervous when assigning Mackenzie a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom does not show any potential in his job per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Morgan sometimes struggles to finish every ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Amaya has been completing work as required, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The employee fully meets the established job e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Braydon Terrell has been a solid performer for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>While I have found some issues with Logan's pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feedback\n",
       "0    Jamie has delivered fantastic results. The wor...\n",
       "1    Jude has potential but needs coaching in sever...\n",
       "2    Alonso has been an outstanding team member and...\n",
       "3    I'm always nervous when assigning Mackenzie a ...\n",
       "4    Tom does not show any potential in his job per...\n",
       "..                                                 ...\n",
       "873  Morgan sometimes struggles to finish every ass...\n",
       "874  Amaya has been completing work as required, bu...\n",
       "875  The employee fully meets the established job e...\n",
       "876  Braydon Terrell has been a solid performer for...\n",
       "877  While I have found some issues with Logan's pe...\n",
       "\n",
       "[878 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "yMhMj8Oczi08",
    "outputId": "c81121b6-691b-464b-b155-976df4e27133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>Tokenized_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jamie has delivered fantastic results. The wor...</td>\n",
       "      <td>[jamie, has, delivered, fantastic, results, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jude has potential but needs coaching in sever...</td>\n",
       "      <td>[jude, has, potential, but, needs, coaching, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonso has been an outstanding team member and...</td>\n",
       "      <td>[alonso, has, been, an, outstanding, team, mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm always nervous when assigning Mackenzie a ...</td>\n",
       "      <td>[i, 'm, always, nervous, when, assigning, mack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom does not show any potential in his job per...</td>\n",
       "      <td>[tom, does, not, show, any, potential, in, his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alfie Wright's work has been substandard this ...</td>\n",
       "      <td>[alfie, wright, 's, work, has, been, substanda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Working individually, Dean has exceeded expect...</td>\n",
       "      <td>[working, individually, ,, dean, has, exceeded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Allan Logan touches anything and it turns to g...</td>\n",
       "      <td>[allan, logan, touches, anything, and, it, tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yahir Harvey ranked at a Category 8. Yahir has...</td>\n",
       "      <td>[yahir, harvey, ranked, at, a, category, 8, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bruno johns is person who performs really grea...</td>\n",
       "      <td>[bruno, johns, is, person, who, performs, real...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            feedback   \n",
       "0  Jamie has delivered fantastic results. The wor...  \\\n",
       "1  Jude has potential but needs coaching in sever...   \n",
       "2  Alonso has been an outstanding team member and...   \n",
       "3  I'm always nervous when assigning Mackenzie a ...   \n",
       "4  Tom does not show any potential in his job per...   \n",
       "5  Alfie Wright's work has been substandard this ...   \n",
       "6  Working individually, Dean has exceeded expect...   \n",
       "7  Allan Logan touches anything and it turns to g...   \n",
       "8  Yahir Harvey ranked at a Category 8. Yahir has...   \n",
       "9  Bruno johns is person who performs really grea...   \n",
       "\n",
       "                                    Tokenized_Review  \n",
       "0  [jamie, has, delivered, fantastic, results, .,...  \n",
       "1  [jude, has, potential, but, needs, coaching, i...  \n",
       "2  [alonso, has, been, an, outstanding, team, mem...  \n",
       "3  [i, 'm, always, nervous, when, assigning, mack...  \n",
       "4  [tom, does, not, show, any, potential, in, his...  \n",
       "5  [alfie, wright, 's, work, has, been, substanda...  \n",
       "6  [working, individually, ,, dean, has, exceeded...  \n",
       "7  [allan, logan, touches, anything, and, it, tur...  \n",
       "8  [yahir, harvey, ranked, at, a, category, 8, .,...  \n",
       "9  [bruno, johns, is, person, who, performs, real...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Lowercase and tokenise all the reviews in train_reviews using spacy'''\n",
    "\n",
    "import spacy\n",
    "encoder = spacy.load('en_core_web_sm')\n",
    "\n",
    "def text_to_tokens(text_seqs):\n",
    "    tokenized = [[word.lower_ for word in encoder(text)] for text in text_seqs]\n",
    "    return tokenized\n",
    "    #complete this function that lowers and tokenizes the reviews\n",
    "\n",
    "\n",
    "train_reviews['Tokenized_Review'] = text_to_tokens(train_reviews['feedback'])\n",
    "train_reviews[['feedback','Tokenized_Review']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Urmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "train_reviews['Tokenized_Review'] = train_reviews['Tokenized_Review'].apply(lambda x: [word for word in x if word not in (stop)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>Tokenized_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jamie has delivered fantastic results. The wor...</td>\n",
       "      <td>[jamie, delivered, fantastic, results, ., work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jude has potential but needs coaching in sever...</td>\n",
       "      <td>[jude, potential, needs, coaching, several, ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonso has been an outstanding team member and...</td>\n",
       "      <td>[alonso, outstanding, team, member, continues,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm always nervous when assigning Mackenzie a ...</td>\n",
       "      <td>['m, always, nervous, assigning, mackenzie, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom does not show any potential in his job per...</td>\n",
       "      <td>[tom, show, potential, job, performance, ., to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Morgan sometimes struggles to finish every ass...</td>\n",
       "      <td>[morgan, sometimes, struggles, finish, every, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Amaya has been completing work as required, bu...</td>\n",
       "      <td>[amaya, completing, work, required, ,, really,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The employee fully meets the established job e...</td>\n",
       "      <td>[employee, fully, meets, established, job, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Braydon Terrell has been a solid performer for...</td>\n",
       "      <td>[braydon, terrell, solid, performer, company, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>While I have found some issues with Logan's pe...</td>\n",
       "      <td>[found, issues, logan, 's, performance, past, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feedback   \n",
       "0    Jamie has delivered fantastic results. The wor...  \\\n",
       "1    Jude has potential but needs coaching in sever...   \n",
       "2    Alonso has been an outstanding team member and...   \n",
       "3    I'm always nervous when assigning Mackenzie a ...   \n",
       "4    Tom does not show any potential in his job per...   \n",
       "..                                                 ...   \n",
       "873  Morgan sometimes struggles to finish every ass...   \n",
       "874  Amaya has been completing work as required, bu...   \n",
       "875  The employee fully meets the established job e...   \n",
       "876  Braydon Terrell has been a solid performer for...   \n",
       "877  While I have found some issues with Logan's pe...   \n",
       "\n",
       "                                      Tokenized_Review  \n",
       "0    [jamie, delivered, fantastic, results, ., work...  \n",
       "1    [jude, potential, needs, coaching, several, ar...  \n",
       "2    [alonso, outstanding, team, member, continues,...  \n",
       "3    ['m, always, nervous, assigning, mackenzie, re...  \n",
       "4    [tom, show, potential, job, performance, ., to...  \n",
       "..                                                 ...  \n",
       "873  [morgan, sometimes, struggles, finish, every, ...  \n",
       "874  [amaya, completing, work, required, ,, really,...  \n",
       "875  [employee, fully, meets, established, job, exp...  \n",
       "876  [braydon, terrell, solid, performer, company, ...  \n",
       "877  [found, issues, logan, 's, performance, past, ...  \n",
       "\n",
       "[878 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcxRMGGzzi09",
    "outputId": "11841b55-e5f3-4528-cdd6-2f01e64ad02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jamie': 2, 'delivered': 3, 'fantastic': 4, 'results': 5, '.': 6, 'work': 7, 'submits': 8, 'regularly': 9, 'better': 10, 'colleagues': 11, ',': 12, 'continues': 13, 'seek': 14, 'feedback': 15, 'continue': 16, 'monitored': 17, 'determine': 18, 'whether': 19, 'would': 20, 'good': 21, 'fit': 22, 'management': 23, 'position': 24, 'improve': 25, 'leadership': 26, 'skills': 27, \"n't\": 28, 'difficult': 29, 'since': 30, 'rapport': 31, 'led': 32, 'many': 33, 'projects': 34, 'success': 35, 'jude': 36, 'potential': 37, 'needs': 38, 'coaching': 39, 'several': 40, 'areas': 41, 'quality': 42, 'poor': 43, 'mistakes': 44, 'talked': 45, 'occasions': 46, 'defensive': 47, 'deny': 48, 'even': 49, 'shown': 50, 'examples': 51, 'also': 52, 'act': 53, 'professional': 54, 'manner': 55, 'take': 56, 'sort': 57, 'well': 58, 'given': 59, 'raise': 60, 'year': 61, 'complete': 62, 'rigid': 63, 'program': 64, 'employment': 65, 'alonso': 66, 'outstanding': 67, 'team': 68, 'member': 69, 'exceed': 70, 'peers': 71, 'strong': 72, 'communicator': 73, 'able': 74, 'make': 75, 'connections': 76, 'almost': 77, 'anyone': 78, 'onboarding': 79, 'buddy': 80, 'new': 81, 'quarter': 82, 'onboard': 83, 'twice': 84, 'fast': 85, 'average': 86, 'continued': 87, 'perform': 88, 'standard': 89, 'deviations': 90, 'ready': 91, 'increased': 92, 'responsibility': 93, \"'m\": 94, 'always': 95, 'nervous': 96, 'assigning': 97, 'mackenzie': 98, 'report': 99, \"'s\": 100, 'turned': 101, 'drafts': 102, 'back': 103, 'frequently': 104, 'find': 105, 'lot': 106, 'glaring': 107, 'typos': 108, 'miscalculations': 109, 'easy': 110, 'catch': 111, 'proofreading': 112, 'ca': 113, 'trust': 114, 'turn': 115, 'clients': 116, 'without': 117, 'least': 118, 'two': 119, 'review': 120, 'first': 121, 'waste': 122, 'resources': 123, 'worse': 124, 'seem': 125, 'really': 126, 'care': 127, 'making': 128, 'improvements': 129, 'thus': 130, 'see': 131, 'moving': 132, 'far': 133, 'organization': 134, 'tom': 135, 'show': 136, 'job': 137, 'performance': 138, 'never': 139, 'seems': 140, 'caught': 141, 'behind': 142, 'bad': 143, 'attitude': 144, 'excuses': 145, 'training': 146, 'sure': 147, 'offering': 148, 'everything': 149, 'help': 150, 'successful': 151, 'career': 152, 'alfie': 153, 'wright': 154, 'substandard': 155, ' ': 156, 'failed': 157, 'hand': 158, '-': 159, 'deliver': 160, 'important': 161, 'filings': 162, 'courthouse': 163, 'clerk': 164, 'office': 165, 'closed': 166, 'fairness': 167, 'however': 168, 'child': 169, 'suffering': 170, 'chronic': 171, 'disorder': 172, 'sapping': 173, 'energy': 174, 'consider': 175, 'greater': 176, 'support': 177, 'reliable': 178, 'courier': 179, 'past': 180, 'working': 181, 'individually': 182, 'dean': 183, 'exceeded': 184, 'expectations': 185, 'lacks': 186, 'basic': 187, 'communication': 188, 'interfere': 189, 'ability': 190, 'integrate': 191, 'within': 192, 'voice': 193, 'heard': 194, 'shortcomings': 195, 'affect': 196, 'project': 197, 'contribution': 198, 'used': 199, 'individual': 200, 'accomplishes': 201, 'tasks': 202, 'suitable': 203, 'role': 204, 'allan': 205, 'logan': 206, 'touches': 207, 'anything': 208, 'turns': 209, 'gold': 210, 'nothing': 211, 'capable': 212, 'achieve': 213, 'dream': 214, 'overall': 215, 'capability': 216, 'asset': 217, 'beacon': 218, 'expertise': 219, 'yahir': 220, 'harvey': 221, 'ranked': 222, 'category': 223, '8': 224, 'come': 225, 'long': 226, 'way': 227, 'shows': 228, 'modeled': 229, 'expect': 230, 'rise': 231, '9': 232, 'time': 233, 'bruno': 234, 'johns': 235, 'person': 236, 'performs': 237, 'great': 238, '.he': 239, 'solid': 240, 'performer': 241, 'best': 242, 'every': 243, 'assigned': 244, '\\n': 245, 'low': 246, 'dennis': 247, 'buchanan': 248, 'acts': 249, 'waiting': 250, 'one': 251, 'day': 252, 'wait': 253, 'future': 254, 'certainly': 255, 'blake': 256, 'rodriguez': 257, 'performed': 258, 'outstandingly': 259, 'improved': 260, 'drastically': 261, 'last': 262, 'taken': 263, 'notice': 264, 'based': 265, 'high': 266, 'believe': 267, 'look': 268, 'forward': 269, 'seeing': 270, 'efforts': 271, 'kyle': 272, 'somewhat': 273, 'improvement': 274, 'although': 275, 'hard': 276, 'appreciable': 277, 'go': 278, 'learn': 279, 'efficiency': 280, 'bobby': 281, 'lowe': 282, 'worked': 283, 'baseball': 284, 'manager': 285, 'coach': 286, 'scout': 287, 'think': 288, 'succesfull': 289, 'life': 290, '  ': 291, 'player': 292, 'earned': 293, 'lots': 294, 'awards': 295, 'chanel': 296, 'rising': 297, 'consistent': 298, 'sometimes': 299, 'little': 300, 'rushed': 301, 'occasionally': 302, 'revise': 303, 'sharper': 304, 'accepts': 305, 'correction': 306, 'takes': 307, 'definite': 308, 'action': 309, 'gt': 310, 'track': 311, 'makenna': 312, 'issues': 313, 'getting': 314, 'started': 315, 'department': 316, 'product': 317, 'errors': 318, 'noticed': 319, 'reports': 320, 'underdeveloped': 321, 'researched': 322, 'said': 323, 'confident': 324, 'ton': 325, 'room': 326, 'growth': 327, 'enthusiastic': 328, 'willing': 329, 'serious': 330, 'changes': 331, 'received': 332, 'serve': 333, 'chelsea': 334, 'stevens': 335, 'excels': 336, 'goal': 337, 'set': 338, 'learner': 339, 'enjoys': 340, 'taking': 341, 'higher': 342, 'valued': 343, 'friendly': 344, 'everyone': 345, 'cheers': 346, 'encourages': 347, 'need': 348, 'aryanna': 349, 'difficulty': 350, 'adjusting': 351, 'place': 352, 'confused': 353, 'unfinished': 354, 'filled': 355, 'motivated': 356, 'change': 357, 'things': 358, 'order': 359, 'us': 360, 'might': 361, 'slowed': 362, 'company': 363, 'keep': 364, 'worker': 365, 'around': 366, 'jay': 367, 'reid': 368, 'level': 369, 'disappointing': 370, 'kind': 371, 'possess': 372, 'right': 373, 'possibly': 374, 'adjustments': 375, 'could': 376, 'despite': 377, 'fully': 378, 'adjusts': 379, 'finds': 380, 'direction': 381, 'pay': 382, 'still': 383, 'finding': 384, 'whatever': 385, 'value': 386, 'madison': 387, 'employee': 388, 'consistently': 389, 'creates': 390, 'highest': 391, 'possible': 392, 'exceeds': 393, 'rarely': 394, 'makes': 395, 'open': 396, 'criticism': 397, 'others': 398, 'seen': 399, 'mistake': 400, 'vastly': 401, 'gains': 402, 'experience': 403, 'kayleigh': 404, 'delight': 405, 'sunny': 406, 'personality': 407, 'positive': 408, 'client': 409, 'asks': 410, 'seemingly': 411, 'impossible': 412, 'turnaround': 413, 'means': 414, 'tackles': 415, 'assignment': 416, 'hesitation': 417, 'overlooks': 418, 'key': 419, 'research': 420, 'questions': 421, 'fix': 422, 'issue': 423, 'often': 424, 'pressed': 425, 'result': 426, 'unrealistic': 427, 'demands': 428, 'try': 429, 'meticulous': 430, 'analysis': 431, 'reasonable': 432, 'prove': 433, 'advance': 434, 'kohen': 435, 'norris': 436, 'lack': 437, 'words': 438, 'incompetent': 439, 'like': 440, 'say': 441, 'regards': 442, 'late': 443, 'smells': 444, 'poorly': 445, 'guidelines': 446, 'feel': 447, 'interest': 448, 'drop': 449, 'impessed': 450, 'frederick': 451, 'rogers': 452, 'fred': 453, 'prefers': 454, 'called': 455, 'outshines': 456, 'competition': 457, 'single': 458, ';': 459, 'goes': 460, 'beyond': 461, 'expected': 462, 'keeps': 463, 'climb': 464, 'infrastructure': 465, 'glad': 466, 'works': 467, '!': 468, 'morgan': 469, 'butler': 470, 'steady': 471, 'recall': 472, 'cranked': 473, 'quite': 474, 'bit': 475, 'discovery': 476, 'amazon': 477, 'matter': 478, 'incisiveness': 479, 'along': 480, 'generally': 481, 'describe': 482, 'adequate': 483, 'trusted': 484, 'everyday': 485, 'mentioned': 486, 'production': 487, 'case': 488, 'isobel': 489, 'foster': 490, 'worst': 491, 'colleague': 492, 'potentially': 493, 'train': 494, 'moment': 495, 'subpar': 496, 'valuable': 497, 'discipline': 498, 'nee': 499, 'increase': 500, 'foremost': 501, 'eloise': 502, 'follower': 503, 'rather': 504, 'leader': 505, 'timely': 506, 'inventive': 507, 'settings': 508, 'gladly': 509, 'lions': 510, 'share': 511, 'contribute': 512, 'ideas': 513, 'let': 514, 'someone': 515, 'else': 516, 'lead': 517, 'writing': 518, 'mr.': 519, 'unfortunately': 520, 'engaging': 521, 'possibility': 522, 'becoming': 523, \"'ve\": 524, 'unhappy': 525, 'dallas': 526, 'count': 527, 'senior': 528, 'mentor': 529, 'less': 530, 'experienced': 531, 'tips': 532, 'strategies': 533, 'turning': 534, 'flawless': 535, 'incredibly': 536, 'detail': 537, 'oriented': 538, 'appreciate': 539, 'effort': 540, 'perfectly': 541, 'free': 542, 'grammar': 543, 'business': 544, 'development': 545, 'developed': 546, 'alex': 547, 'stable': 548, 'required': 549, 'necessary': 550, 'minimal': 551, 'understand': 552, 'communicates': 553, 'amount': 554, 'encourage': 555, 'additional': 556, 'assist': 557, 'absolutely': 558, 'astounding': 559, 'finishes': 560, 'early': 561, 'furthermore': 562, 'learns': 563, '(': 564, ')': 565, 'proactively': 566, 'improves': 567, 'seeks': 568, 'wonderful': 569, 'get': 570, 'whitehead': 571, 'careful': 572, 'delivers': 573, 'firm': 574, 'gavyn': 575, 'productivity': 576, 'substantially': 577, 'lateral': 578, 'movement': 579, 'upwards': 580, 'near': 581, 'perhaps': 582, 'suggest': 583, 'volume': 584, 'slow': 585, 'burnout': 586, 'small': 587, 'suggestion': 588, 'executed': 589, 'wade': 590, 'meaningful': 591, 'willingness': 592, 'grow': 593, 'isaac': 594, 'tough': 595, 'showed': 596, 'gets': 597, 'head': 598, 'hire': 599, 'period': 600, 'accommodate': 601, 'multiple': 602, 'deadlines': 603, 'short': 604, 'bring': 605, 'teams': 606, 'together': 607, 'easily': 608, 'understands': 609, 'behavior': 610, 'overcome': 611, 'barriers': 612, 'shape': 613, 'send': 614, 'directly': 615, 'much': 616, 'part': 617, 'pays': 618, 'close': 619, 'attention': 620, 'details': 621, 'unwilling': 622, 'draft': 623, 'deems': 624, 'perfect': 625, 'misses': 626, 'spoken': 627, 'focus': 628, 'area': 629, 'perfectionist': 630, \"'ll\": 631, 'significant': 632, 'contributor': 633, 'months': 634, 'know': 635, 'hope': 636, 'ways': 637, 'contributions': 638, '?': 639, 'liked': 640, 'weeks': 641, 'meetings': 642, 'drove': 643, 'directions': 644, 'thought': 645, 'otherwise': 646, 'specific': 647, '...': 648, \"'re\": 649, 'times': 650, 'emilia': 651, 'produces': 652, 'concern': 653, 'respond': 654, 'complacent': 655, 'want': 656, 'happy': 657, 'current': 658, 'skill': 659, 'skilled': 660, 'unlikely': 661, 'compromise': 662, 'completing': 663, 'background': 664, 'qualifies': 665, 'unable': 666, 'assignments': 667, 'missed': 668, 'mandatory': 669, 'sessions': 670, 'use': 671, 'word': 672, 'got': 673, 'old': 674, 'school': 675, 'blue': 676, 'collar': 677, 'ethic': 678, 'done': 679, 'pace': 680, 'blowing': 681, 'away': 682, 'intangibles': 683, 'indicate': 684, 'worth': 685, 'investing': 686, 'move': 687, 'whole': 688, 'lexi': 689, 'instances': 690, 'meet': 691, 'established': 692, 'expectation': 693, 'extended': 694, 'task': 695, 'initially': 696, 'timeline': 697, 'establish': 698, 'completion': 699, 'check': 700, 'ensure': 701, 'progress': 702, 'consistency': 703, 'david': 704, 'kelly': 705, 'proven': 706, 'thoroughly': 707, 'already': 708, 'maintains': 709, 'employees': 710, 'perdo': 711, 'efficiently': 712, 'pedro': 713, 'meeting': 714, 'numbers': 715, 'operating': 716, 'capacity': 717, 'john': 718, 'progressed': 719, 'continuously': 720, 'leaves': 721, 'breaks': 722, 'throughout': 723, 'calls': 724, 'week': 725, 'fridays': 726, 'significantly': 727, 'declined': 728, 'jaden': 729, 'assign': 730, 'sharp': 731, 'eye': 732, 'spotting': 733, 'gaps': 734, 'sloppy': 735, 'copy': 736, 'editing': 737, 'duties': 738, 'spend': 739, 'half': 740, 'hour': 741, 'cleaning': 742, 'provides': 743, 'problem': 744, 'span': 745, 'default': 746, 'simply': 747, 'manages': 748, 'told': 749, 'committed': 750, 'gunner': 751, 'members': 752, 'rates': 753, 'normally': 754, 'ranks': 755, 'scale': 756, 'outlook': 757, 'abilities': 758, 'knows': 759, 'strengths': 760, 'uses': 761, 'advantage': 762, 'may': 763, 'eventually': 764, 'material': 765, 'riley': 766, 'excellent': 767, 'whenever': 768, 'offers': 769, '\"': 770, 'big': 771, 'picture': 772, 'vision': 773, 'freya': 774, 'comes': 775, 'teaching': 776, 'relying': 777, '100': 778, '%': 779, 'independently': 780, 'indication': 781, 'handle': 782, 'pressures': 783, 'responsibilities': 784, 'jobs': 785, 'ladder': 786, 'accomplish': 787, 'constant': 788, 'motivation': 789, 'encouragement': 790, 'ava': 791, 'coming': 792, 'bringing': 793, 'idea': 794, 'provide': 795, 'usefull': 796, 'sometime': 797, 'distracted': 798, 'affecting': 799, 'listen': 800, 'space': 801, 'carl': 802, 'hiss': 803, 'workplace': 804, 'excelled': 805, 'pride': 806, 'extra': 807, 'put': 808, 'ideal': 809, 'took': 810, 'paid': 811, 'emilie': 812, 'completes': 813, 'promoted': 814, 'next': 815, '6': 816, 'braiden': 817, 'reached': 818, 'quotas': 819, 'solutions': 820, 'internal': 821, 'problems': 822, 'industry': 823, 'term': 824, 'investment': 825, 'produce': 826, 'margaret': 827, 'quick': 828, 'filing': 829, 'putting': 830, 'went': 831, 'passes': 832, 'highten': 833, 'alina': 834, 'previous': 835, 'usable': 836, 'remarkable-': 837, 'triple': 838, 'checks': 839, 'clear': 840, 'concise': 841, 'stated': 842, 'michael': 843, 'completed': 844, 'strive': 845, 'offer': 846, 'bare': 847, 'minimum': 848, 'exhibit': 849, 'drive': 850, 'shine': 851, 'description': 852, 'entire': 853, 'group': 854, 'goals': 855, 'prosperous': 856, 'ahead': 857, 'likely': 858, 'demonstrate': 859, 'detailed': 860, 'orientated': 861, 'responds': 862, 'pretty': 863, 'coworkers': 864, 'usually': 865, 'tries': 866, 'concepts': 867, 'nt': 868, 'guidance': 869, 'bryleigh': 870, 'stafford': 871, 'proficient': 872, 'demonstrates': 873, 'doe': 874, 'knowledge': 875, 'procedures': 876, 'comply': 877, 'output': 878, 'standards': 879, 'reluctant': 880, 'declan': 881, 'houghton': 882, 'finishing': 883, 'managed': 884, 'hoping': 885, 'popular': 886, 'intuitively': 887, 'requests': 888, 'error': 889, 'spot': 890, 'checking': 891, 'final': 892, 'copies': 893, 'regard': 894, 'asking': 895, 'proactive': 896, 'diligent': 897, 'enough': 898, 'implement': 899, 'advice': 900, 'azariah': 901, 'talented': 902, 'superb': 903, 'creative': 904, 'storylines': 905, 'generates': 906, 'advertising': 907, 'pitches': 908, 'screen': 909, 'routinely': 910, 'impressed': 911, 'performing': 912, 'become': 913, 'executive': 914, 'george': 915, 'struggles': 916, 'give': 917, 'though': 918, 'ask': 919, 'menial': 920, 'spelling': 921, 'needed': 922, 'second': 923, 'eyes': 924, 'reason': 925, 'rushes': 926, 'thinking': 927, 'emphasized': 928, 'speed': 929, 'heart': 930, 'darius': 931, 'example': 932, 'trainee': 933, 'field': 934, 'respectful': 935, 'cooperative': 936, 'addition': 937, 'noah': 938, 'substantial': 939, 'beaten': 940, 'timelines': 941, 'certain': 942, 'closely': 943, 'trusting': 944, 'decisions': 945, 'impressive': 946, 'sonny': 947, 'full': 948, 'game': 949, 'brings': 950, 'continueings': 951, 'friend': 952, 'matthew': 953, 'finest': 954, 'division': 955, 'fails': 956, 'apply': 957, 'reaching': 958, 'ventures': 959, 'love': 960, 'recruit': 961, 'wo': 962, 'pour': 963, 'leave': 964, 'bigger': 965, 'clay': 966, 'terry': 967, 'process': 968, 'techniques': 969, 'contributed': 970, 'unit': 971, 'maintained': 972, 'productive': 973, 'relationships': 974, 'co': 975, 'workers': 976, 'sharpness': 977, 'understanding': 978, 'core': 979, 'purposes': 980, 'radiantly': 981, 'weekly': 982, 'basis': 983, 'structural': 984, 'choices': 985, 'software': 986, 'programs': 987, 'proved': 988, 'quarterly': 989, 'niko': 990, 'oliver': 991, 'amazing': 992, 'stunning': 993, 'captivating': 994, 'performances': 995, 'rest': 996, 'feeling': 997, 'provoking': 998, 'scenes': 999, 'incredible': 1000, 'gifts': 1001, 'highly': 1002, 'recommend': 1003, 'watching': 1004, 'emotion': 1005, 'forefront': 1006, 'jessica': 1007, 'hardworking': 1008, 'accurate': 1009, 'achieved': 1010, 'point': 1011, 'challenge': 1012, 'loves': 1013, 'sophie': 1014, 'lovable': 1015, 'fun': 1016, 'masks': 1017, 'fact': 1018, 'meant': 1019, 'cooped': 1020, 'desk': 1021, 'pushing': 1022, 'papers': 1023, 'social': 1024, 'warmth': 1025, \"'d\": 1026, 'interaction': 1027, 'hr': 1028, 'public': 1029, 'relations': 1030, 'community': 1031, 'amelie': 1032, 'fickle': 1033, 'minded': 1034, 'irregular': 1035, 'attending': 1036, '&': 1037, 'listening': 1038, 'properly': 1039, 'answer': 1040, 'queries': 1041, 'emails': 1042, 'maintain': 1043, 'proper': 1044, 'balance': 1045, 'personal': 1046, 'unprofessional': 1047, 'seniors': 1048, 'spite': 1049, 'talent': 1050, 'guided': 1051, 'start': 1052, 'detrimental': 1053, 'rehiring': 1054, 'isabella': 1055, 'james': 1056, 'paycheck': 1057, 'advancement': 1058, 'active': 1059, 'improving': 1060, 'handles': 1061, 'instruction': 1062, 'requirements': 1063, 't.': 1064, 'burgess': 1065, 'fair': 1066, 'display': 1067, 'adept': 1068, 'accomplishing': 1069, 'engage': 1070, 'passion': 1071, 'rachel': 1072, 'turner': 1073, 'stellar': 1074, 'chances': 1075, 'continuing': 1076, 'determination': 1077, 'finish': 1078, 'knew': 1079, 'emerson': 1080, 'rose': 1081, 'medium': 1082, 'complexity': 1083, 'complex': 1084, 'quickly': 1085, 'adapt': 1086, 'inasmuch': 1087, 'learning': 1088, 'curve': 1089, 'steep': 1090, 'relatively': 1091, 'items': 1092, 'sharing': 1093, 'dylan': 1094, 'baker': 1095, 'counted': 1096, 'patient': 1097, 'step': 1098, 'libby': 1099, 'associate': 1100, 'careless': 1101, 'hesitant': 1102, 'shy': 1103, 'speaking': 1104, 'hours': 1105, '20': 1106, 'minutes': 1107, 'moreover': 1108, 'listens': 1109, 'seriously': 1110, 'imagine': 1111, 'longer': 1112, 'tenure': 1113, 'demonstrated': 1114, 'capably': 1115, 'flashes': 1116, 'growing': 1117, 'currently': 1118, 'stands': 1119, 'nolan': 1120, 'jacobson': 1121, 'rating': 1122, 'evaluation': 1123, 'simple': 1124, 'repetitive': 1125, 'require': 1126, 'degree': 1127, 'analytical': 1128, 'quantitative': 1129, 'straightforward': 1130, 'yes': 1131, 'outcomes': 1132, 'crunch': 1133, 'large': 1134, 'desire': 1135, 'invest': 1136, 'dedication': 1137, 'independent': 1138, 'additionally': 1139, 'punctual': 1140, 'lastly': 1141, 'joy': 1142, 'diligently': 1143, 'pursues': 1144, 'determined': 1145, 'initiative': 1146, 'bay': 1147, 'warnings': 1148, 'upto': 1149, 'tried': 1150, 'speak': 1151, 'thoughts': 1152, 'kieran': 1153, 'linchpin': 1154, 'dependable': 1155, 'moderate': 1156, 'interpersonal': 1157, 'acevedo': 1158, 'supervisor': 1159, 'contact': 1160, 'helps': 1161, 'excel': 1162, 'watts': 1163, 'favorite': 1164, 'people': 1165, 'essential': 1166, 'foundation': 1167, 'truly': 1168, 'gunnar': 1169, 'herrera': 1170, 'succeeded': 1171, 'fulfilling': 1172, 'market': 1173, 'interacted': 1174, 'professionally': 1175, 'processes': 1176, 'hawkins': 1177, 'repeatedly': 1178, 'assists': 1179, 'roles': 1180, 'confidence': 1181, 'heavier': 1182, 'load': 1183, 'promise': 1184, 'respect': 1185, 'something': 1186, 'harnessing': 1187, 'enthusiasm': 1188, 'inner': 1189, 'balancing': 1190, 'plate': 1191, 'judicious': 1192, 'covers': 1193, 'bases': 1194, 'sophisticated': 1195, 'arguments': 1196, 'adaptation': 1197, 'outgoing': 1198, 'playmaker': 1199, 'shoot': 1200, 'definitely': 1201, 'usual': 1202, 'rotation': 1203, 'players': 1204, 'defense': 1205, 'holding': 1206, 'exactly': 1207, 'camille': 1208, 'changed': 1209, 'preferences': 1210, '\\r ': 1211, 'classes': 1212, 'unmatched': 1213, '\\r': 1214, 'deteriorating': 1215, 'regular': 1216, 'student': 1217, 'class': 1218, 'complaints': 1219, 'worry': 1220, 'clarke': 1221, 'approach': 1222, 'crossed': 1223, 'path': 1224, 'intent': 1225, 'nurtured': 1226, 'regularity': 1227, 'commitment': 1228, 'cooke': 1229, 'terms': 1230, 'amaya': 1231, 'cross': 1232, 'functional': 1233, 'hesitates': 1234, 'views': 1235, 'known': 1236, 'points': 1237, 'visibility': 1238, 'across': 1239, 'probably': 1240, 'met': 1241, 'maximum': 1242, 'grade': 1243, 'santos': 1244, ':': 1245, 'volunteers': 1246, 'tends': 1247, 'invaluable': 1248, 'enjoy': 1249, 'supportive': 1250, 'encouraging': 1251, 'blew': 1252, 'wish': 1253, 'chandler': 1254, 'spotter': 1255, 'norm': 1256, 'challenger': 1257, 'collaborator': 1258, 'katherine': 1259, 'signs': 1260, 'caring': 1261, 'lower': 1262, 'organizing': 1263, 'spreadsheets': 1264, 'listed': 1265, 'resume': 1266, 'puts': 1267, 'resource': 1268, 'busy': 1269, 'supervision': 1270, 'following': 1271, 'gradually': 1272, 'realize': 1273, 'page': 1274, 'outset': 1275, 'communicate': 1276, 'please': 1277, 'dedicate': 1278, 'events': 1279, 'benefits': 1280, 'cain': 1281, 'month': 1282, 'ray': 1283, 'sunshine': 1284, '..': 1285, 'gives': 1286, '110': 1287, 'percent': 1288, 'likes': 1289, 'feels': 1290, 'customers': 1291, 'liking': 1292, 'thursday': 1293, 'rude': 1294, 'removed': 1295, 'floor': 1296, 'frustrated': 1297, 'inconsistent': 1298, 'clarification': 1299, 'unwillingness': 1300, 'opportunities': 1301, 'hold': 1302, 'run': 1303, 'finley': 1304, 'extremely': 1305, 'attentive': 1306, 'mile': 1307, 'skillful': 1308, 'communicating': 1309, 'succeeding': 1310, 'leading': 1311, 'constantly': 1312, 'supervised': 1313, 'due': 1314, 'submit': 1315, 'intelligent': 1316, 'incentive': 1317, 'made': 1318, 'choose': 1319, 'different': 1320, 'ignite': 1321, 'ambition': 1322, 'lazy': 1323, 'cristian': 1324, 'levels': 1325, 'promising': 1326, 'equates': 1327, 'critical': 1328, 'moments': 1329, 'grey': 1330, 'follows': 1331, 'forth': 1332, 'letter': 1333, 'insights': 1334, 'correct': 1335, 'benefit': 1336, 'outside': 1337, 'box': 1338, 'basically': 1339, 'briley': 1340, 'mcknight': 1341, 'recent': 1342, 'days': 1343, 'update': 1344, 'concentrate': 1345, 'updated': 1346, 'technology': 1347, 'promptly': 1348, 'actions': 1349, 'hannah': 1350, 'satisfactory': 1351, 'polish': 1352, 'top': 1353, 'tier': 1354, 'asked': 1355, 'immediately': 1356, 'trying': 1357, 'navigate': 1358, 'particularly': 1359, 'sticky': 1360, 'legal': 1361, 'thinks': 1362, 'versed': 1363, 'statues': 1364, 'codes': 1365, 'inform': 1366, 'uninterested': 1367, 'piece': 1368, 'touch': 1369, 'partners': 1370, 'master': 1371, 'benjamin': 1372, 'roberts': 1373, 'coworker': 1374, 'relied': 1375, 'upon': 1376, 'pleasant': 1377, 'rushing': 1378, 'clocking': 1379, 'underperforming': 1380, 'trouble': 1381, 'informations': 1382, 'eager': 1383, 'weaker': 1384, 'brynlee': 1385, 'rely': 1386, 'advise': 1387, 'supervisory': 1388, 'jayden': 1389, 'rees': 1390, 'intuitive': 1391, 'input': 1392, 'insightful': 1393, 'original': 1394, 'decreased': 1395, 'lately': 1396, 'wander': 1397, 'actually': 1398, 'decent': 1399, 'budget': 1400, 'helped': 1401, 'build': 1402, 'efficient': 1403, 'finally': 1404, 'besides': 1405, 'added': 1406, 'elements': 1407, 'deliverable': 1408, 'specifications': 1409, 'enhanced': 1410, 'outcome': 1411, 'terrible': 1412, 'hurt': 1413, 'mcmillan': 1414, 'rated': 1415, 'joined': 1416, 'interested': 1417, 'aspects': 1418, 'dedicated': 1419, 'presenting': 1420, 'stylish': 1421, 'april': 1422, 'craft': 1423, 'typical': 1424, 'hopefully': 1425, 'arriving': 1426, 'mood': 1427, 'double': 1428, 'chance': 1429, 'gill': 1430, 'found': 1431, 'struggling': 1432, 'counselling': 1433, 'par': 1434, 'reflects': 1435, 'qualities': 1436, 'continuous': 1437, 'matches': 1438, 'inconsistency': 1439, 'teamhe': 1440, 'exemplary': 1441, '.his': 1442, 'represents': 1443, 'organisation': 1444, 'peter': 1445, 'allen': 1446, 'smart': 1447, 'compared': 1448, 'graysen': 1449, 'looking': 1450, 'explain': 1451, 'challenging': 1452, 'gain': 1453, 'exposure': 1454, 'succeed': 1455, 'self-': 1456, 'directed': 1457, 'meaning': 1458, 'schedule': 1459, 'effective': 1460, 'duty': 1461, 'going': 1462, 'freddie': 1463, 'understatement': 1464, 'flooded': 1465, 'phone': 1466, 'ongoing': 1467, 'pandemic': 1468, '7': 1469, 'unplanned': 1470, 'citing': 1471, 'emergency': 1472, 'blatant': 1473, 'lie': 1474, 'according': 1475, 'media': 1476, 'accounts': 1477, 'wise': 1478, 'alarmingly': 1479, 'redeem': 1480, 'swiftly': 1481, 'becomes': 1482, 'requires': 1483, 'develop': 1484, 'plan': 1485, 'objectives': 1486, 'written': 1487, 'follow': 1488, 's.': 1489, 'mid': 1490, 'showing': 1491, 'greatly': 1492, 'exhibiting': 1493, 'prefer': 1494, 'esmerelda': 1495, 'langley': 1496, 'jalen': 1497, 'summers': 1498, 'distaste': 1499, 'shift': 1500, 'resolved': 1501, 'soon': 1502, 'mark': 1503, 'man': 1504, 'thanks': 1505, 'fundamentals': 1506, 'depth': 1507, 'road': 1508, 'knowing': 1509, 'deeply': 1510, 'trumps': 1511, 'breadth': 1512, 'gray': 1513, 'mr': 1514, 'begins': 1515, 'idle': 1516, 'proud': 1517, 'guy': 1518, 'lacking': 1519, 'attributes': 1520, 'kept': 1521, 'huge': 1522, 'weak': 1523, 'competencies': 1524, 'pillars': 1525, 'front': 1526, 'fresh': 1527, 'young': 1528, 'blood': 1529, 'managing': 1530, 'light': 1531, 'natasha': 1532, 'richardson': 1533, 'peak': 1534, 'producer': 1535, 'logging': 1536, '600': 1537, 'billable': 1538, 'contacts': 1539, 'securing': 1540, 'likelihood': 1541, 'aspires': 1542, 'house': 1543, 'counsel': 1544, 'consequently': 1545, 'tepid': 1546, 'rate': 1547, 'amy': 1548, '2': 1549, 'partnered': 1550, 'building': 1551, 'exercises': 1552, 'unenthusiastic': 1553, 'participate': 1554, 'fairly': 1555, 'tend': 1556, 'satisfied': 1557, 'ok': 1558, 'wants': 1559, 'influence': 1560, 'aptitude': 1561, 'limited': 1562, 'middle': 1563, 'pack': 1564, 'self': 1565, 'surpassed': 1566, 'sales': 1567, 'target': 1568, '72': 1569, 'massively': 1570, 'contributing': 1571, 'win': 1572, 'summer': 1573, 'sale': 1574, 'bonanza': 1575, 'pleased': 1576, 'announce': 1577, 'appointment': 1578, 'hot': 1579, 'inspiration': 1580, 'lets': 1581, 'footsteps': 1582, 'murray': 1583, 'reply': 1584, 'workflow': 1585, 'date': 1586, 'data': 1587, 'encouraged': 1588, 'actively': 1589, 'discussions': 1590, 'daniel': 1591, 'starting': 1592, 'motivate': 1593, 'supervisors': 1594, 'brantley': 1595, 'impacted': 1596, 'negative': 1597, 'cut': 1598, 'slack': 1599, 'questioning': 1600, 'approaching': 1601, 'doubt': 1602, 'impacts': 1603, 'impression': 1604, 'fortunately': 1605, 'shaky': 1606, 'number': 1607, 'ropes': 1608, 'package': 1609, 'generated': 1610, 'checked': 1611, 'computational': 1612, 'enrolled': 1613, 'aspect': 1614, 'frustrating': 1615, 'return': 1616, 'attend': 1617, 'riddled': 1618, 'corrections': 1619, 'instructions': 1620, 'spectacular': 1621, 'correctly': 1622, 'natural': 1623, 'intelligence': 1624, 'addison': 1625, 'cohen': 1626, 'and/or': 1627, 'setting': 1628, 'pick': 1629, '3': 1630, 'occurred': 1631, 'facility': 1632, 'provided': 1633, 'deal': 1634, 'grasped': 1635, 'specifically': 1636, 'appropriately': 1637, 'clean': 1638, 'restrooms': 1639, 'especially': 1640, 'men': 1641, 'rooms': 1642, 'uncomfortable': 1643, 'urinals': 1644, 'gloves': 1645, 'anti': 1646, 'bacterial': 1647, 'cleaner': 1648, 'face': 1649, 'type': 1650, 'explaining': 1651, 'felt': 1652, 'became': 1653, 'comfortable': 1654, 'later': 1655, 'replied': 1656, 'positions': 1657, 'succeeds': 1658, 'meets': 1659, 'exceeding': 1660, 'achieves': 1661, 'lacey': 1662, 'thomas': 1663, 'ups': 1664, 'downs': 1665, 'shining': 1666, 'star': 1667, 'producing': 1668, 'gamble': 1669, 'lauren': 1670, 'struggled': 1671, 'disappointed': 1672, 'address': 1673, 'three': 1674, 'completely': 1675, 'redo': 1676, 'requested': 1677, 'sick': 1678, 'flu': 1679, 'catching': 1680, 'workload': 1681, 'isolated': 1682, 'repeated': 1683, 'push': 1684, 'true': 1685, 'passions': 1686, 'allowing': 1687, 'explore': 1688, 'options': 1689, 'allow': 1690, 'thrive': 1691, 'presentation': 1692, 'command': 1693, 'presence': 1694, 'suffers': 1695, 'preparation': 1696, 'rehearsed': 1697, 'presentations': 1698, 'flounders': 1699, 'presenter': 1700, 'budgets': 1701, 'rehearsal': 1702, 'workday': 1703, 'pitch': 1704, 'davies': 1705, 'onboarded': 1706, 'ago': 1707, 'partially': 1708, 'maintaining': 1709, 'skillset': 1710, 'innate': 1711, 'talents': 1712, 'functioning': 1713, 'caiden': 1714, 'disruptive': 1715, 'browsing': 1716, 'internet': 1717, 'toby': 1718, 'real': 1719, 'volumes': 1720, 'regional': 1721, 'surprise': 1722, 'another': 1723, 'minor': 1724, 'collaborating': 1725, 'virtually': 1726, 'instant': 1727, 'messaging': 1728, 'app': 1729, 'odd': 1730, 'douglas': 1731, 'sound': 1732, 'apathetic': 1733, 'applies': 1734, 'daily': 1735, 'finlay': 1736, 'expand': 1737, 'sphere': 1738, 'uptick': 1739, 'searching': 1740, 'promotion': 1741, 'celine': 1742, 'power': 1743, 'conviction': 1744, 'documents': 1745, 'impeccable': 1746, 'precise': 1747, 'entrusted': 1748, 'activities': 1749, 'worthy': 1750, 'recognition': 1751, 'creativity': 1752, 'relevant': 1753, '.eventhough': 1754, 'perfection': 1755, 'sincerely': 1756, 'mind': 1757, 'innovative': 1758, 'solve': 1759, 'unique': 1760, 'afraid': 1761, 'experiment': 1762, 'tools': 1763, '/': 1764, 'technologies': 1765, 'stood': 1766, 'crowd': 1767, 'beat': 1768, 'solving': 1769, 'pair': 1770, 'pressure': 1771, 'erin': 1772, 'roadblock': 1773, 'break': 1774, 'utilize': 1775, 'laid': 1776, \"it't\": 1777, 'history': 1778, 'experiences': 1779, 'must': 1780, 'entirely': 1781, 'outperform': 1782, 'eagerly': 1783, 'scope': 1784, 'challenges': 1785, 'complains': 1786, 'ones': 1787, 'executes': 1788, 'flawlessly': 1789, 'analysts': 1790, 'verbal': 1791, 'abrasive': 1792, 'respected': 1793, 'figure': 1794, 'successfully': 1795, 'resolves': 1796, 'admire': 1797, 'cleveland': 1798, 'operate': 1799, 'perfors': 1800, 'present': 1801, 'engages': 1802, 'unsure': 1803, 'gallagher': 1804, 'interview': 1805, 'hired': 1806, 'exemplified': 1807, 'handful': 1808, 'beginning': 1809, 'end': 1810, 'approachable': 1811, 'selfless': 1812, 'coffee': 1813, 'donuts': 1814, 'numerous': 1815, 'moises': 1816, 'houston': 1817, 'instrumental': 1818, 'straight': 1819, 'line': 1820, 'dipped': 1821, 'achievements': 1822, 'kayden': 1823, 'hill': 1824, 'lowest': 1825, 'assistance': 1826, 'immediate': 1827, 'choice': 1828, 'dismiss': 1829, 'harmful': 1830, 'effect': 1831, 'changing': 1832, 'scheduled': 1833, 'opportunity': 1834, 'related': 1835, 'grateful': 1836, 'steps': 1837, 'volunteer': 1838, 'reviewing': 1839, 'painstaking': 1840, 'director': 1841, 'edward': 1842, 'performers': 1843, 'refined': 1844, 'straying': 1845, 'strategy': 1846, 'loss': 1847, 'revenue': 1848, 'statistics': 1849, 'profitability': 1850, 'plans': 1851, 'pursue': 1852, 'terrific': 1853, 'solved': 1854, 'p1': 1855, 'bugs': 1856, 'relative': 1857, 'ease': 1858, 'sadly': 1859, 'carelessness': 1860, 'introduced': 1861, 'totally': 1862, 'avoidable': 1863, 'p2': 1864, 'iron': 1865, 'kinks': 1866, 'concentration': 1867, 'focuses': 1868, 'jamari': 1869, 'deadline': 1870, 'occasion': 1871, 'refused': 1872, 'hit': 1873, 'unfortunate': 1874, 'cover': 1875, 'harder': 1876, 'limits': 1877, 'yet': 1878, 'finished': 1879, 'prioritize': 1880, 'award': 1881, 'winning': 1882, 'deserving': 1883, 'smashes': 1884, 'nicole': 1885, 'situations': 1886, 'control': 1887, 'practices': 1888, 'mentored': 1889, 'baily': 1890, 'acceptable': 1891, 'joseph': 1892, 'burke': 1893, 'policies': 1894, 'sightly': 1895, 'enthusiast': 1896, 'driven.can': 1897, 'acheive': 1898, 'targets': 1899, 'larger': 1900, 'interactions': 1901, 'enable': 1902, 'abysmal': 1903, 'feed': 1904, 'equation': 1905, 'math': 1906, 'signed': 1907, 'bootcamp': 1908, 'conference': 1909, 'attendance': 1910, 'proves': 1911, 'developing': 1912, 'bethany': 1913, 'cunningham': 1914, 'perfecting': 1915, 'optimal': 1916, 'nurture': 1917, 'resilience': 1918, 'foot': 1919, 'wrong': 1920, 'allows': 1921, 'discuss': 1922, 'stage': 1923, 'mean': 1924, 'receive': 1925, 'angelica': 1926, 'younger': 1927, 'collaborates': 1928, 'stickler': 1929, 'left': 1930, 'abrupt': 1931, 'agreed': 1932, 'acknowledged': 1933, 'bright': 1934, 'awful': 1935, 'ignores': 1936, 'helpful': 1937, 'thank': 1938, 'wavering': 1939, 'ethic-': 1940, 'patricia': 1941, 'knowledgeable': 1942, 'earmark': 1943, 'remains': 1944, 'calm': 1945, 'groups': 1946, 'considerate': 1947, 'moral': 1948, 'deepen': 1949, 'graduated': 1950, 'college': 1951, 'concentrated': 1952, 'subject': 1953, 'studying': 1954, 'campus': 1955, 'held': 1956, 'laziness': 1957, 'sad': 1958, 'hear': 1959, 'studies': 1960, 'henry': 1961, 'argues': 1962, 'disrespectful': 1963, 'consideration': 1964, 'liability': 1965, 'useful': 1966, 'feedbacks': 1967, 'request': 1968, 'validation': 1969, 'stages': 1970, 'excellency': 1971, 'five': 1972, 'gave': 1973, 'jeopardizing': 1974, 'spoke': 1975, 'family': 1976, 'emergencies': 1977, 'caused': 1978, 'promised': 1979, 'glimmers': 1980, 'joel': 1981, 'fallen': 1982, 'companies': 1983, 'somebody': 1984, 'sacrifice': 1985, 'helping': 1986, 'risk': 1987, 'organized': 1988, 'constructive': 1989, 'perseveres': 1990, 'expert': 1991, 'passionate': 1992, 'model': 1993, '24': 1994, 'blame': 1995, 'runs': 1996, 'personnel': 1997, 'involving': 1998, 'adapted': 1999, 'readily': 2000, 'relating': 2001, 'style': 2002, 'previously': 2003, 'staying': 2004, 'appreciates': 2005, 'integrated': 2006, 'apparent': 2007, 'began': 2008, 'stand': 2009, 'settles': 2010, 'importantly': 2011, 'applying': 2012, 'complain': 2013, 'e': 2014, 'mail': 2015, 'shannon': 2016, 'clearing': 2017, 'recommended': 2018, 'spellchecks': 2019, 'proofreads': 2020, 'toward': 2021, 'matters': 2022, 'shrugged': 2023, 'responses': 2024, 'returning': 2025, 'ollie': 2026, 'mason': 2027, 'manage': 2028, 'bailey': 2029, 'delivering': 2030, 'keen': 2031, 'participating': 2032, '\\n\\n': 2033, 'exceptional': 2034, 'venture': 2035, 'patchy': 2036, 'striving': 2037, 'assigns': 2038, 'professionalism': 2039, 'years': 2040, 'sellers': 2041, 'phenomenal': 2042, 'vague': 2043, 'ingenious': 2044, 'solution': 2045, 'sky': 2046, 'limit': 2047, 'claimed': 2048, 'evident': 2049, 'excelling': 2050, 'andy': 2051, 'kennedy': 2052, 'varied': 2053, 'rewarding': 2054, 'contain': 2055, 'numerical': 2056, 'formatting': 2057, 'stay': 2058, 'revising': 2059, 'slowing': 2060, 'pressured': 2061, 'stronger': 2062, 'jade': 2063, 'main': 2064, 'informed': 2065, 'presented': 2066, 'jaxson': 2067, 'giles': 2068, 'cause': 2069, 'fits': 2070, 'involved': 2071, 'socialising': 2072, 'remove': 2073, 'competent': 2074, 'technical': 2075, 'capabilities': 2076, 'coding': 2077, 'question': 2078, 'promoting': 2079, 'facing': 2080, 'frequent': 2081, 'operations': 2082, 'produced': 2083, 'requirement': 2084, 'hoped': 2085, 'displays': 2086, 'adapting': 2087, 'max': 2088, 'joe': 2089, 'absolute': 2090, 'assessing': 2091, 'innovate': 2092, 'relaxed': 2093, 'ceiling': 2094, 'elliot': 2095, 'flawed': 2096, 'ever': 2097, 'proofread': 2098, 'edit': 2099, 'evidence': 2100, 'conner': 2101, 'mcintyre': 2102, 'facet': 2103, 'non': 2104, 'environment': 2105, 'stretch': 2106, 'imagination': 2107, 'neither': 2108, 'mediocrity': 2109, 'nonetheless': 2110, 'greatest': 2111, 'gift': 2112, 'presents': 2113, 'employer': 2114, 'quiet': 2115, 'availability': 2116, 'thankful': 2117, 'covered': 2118, 'revisions': 2119, 'seemed': 2120, 'lost': 2121, 'trainings': 2122, 'rockstar': 2123, 'hands': 2124, 'catches': 2125, 'smallest': 2126, 'nit': 2127, 'picky': 2128, \"'\": 2129, 'saves': 2130, 'harsh': 2131, 'vowed': 2132, 'habit': 2133, 'smooths': 2134, 'edges': 2135, 'prime': 2136, 'execution': 2137, 'typically': 2138, 'situation': 2139, 'surprises': 2140, '25': 2141, 'dealership': 2142, 'dealing': 2143, 'termination': 2144, '7th': 2145, 'vehicle': 2146, 'understood': 2147, 'closing': 2148, 'decided': 2149, 'expecting': 2150, 'salesperson': 2151, 'husband': 2152, '8th': 2153, '9th': 2154, 'lease': 2155, '   ': 2156, 'special': 2157, ':)': 2158, 'dull': 2159, 'smile': 2160, 'delay': 2161, 'either': 2162, 'relationship': 2163, 'extraordinary': 2164, 'praise': 2165, 'anywhere': 2166, 'litany': 2167, 'leads': 2168, 'revealed': 2169, 'lags': 2170, 'hinder': 2171, 'generate': 2172, 'exemplar': 2173, 'alongside': 2174, '10': 2175, 'showcases': 2176, 'atmosphere': 2177, 'creating': 2178, 'methodical': 2179, 'condition': 2180, 'envision': 2181, '--': 2182, 'necessarily': 2183, 'receptive': 2184, 'comments': 2185, 'theodor': 2186, 'exhibits': 2187, 'accept': 2188, 'engagements': 2189, 'offered': 2190, 'powerhouse': 2191, 'excited': 2192, 'holds': 2193, 'ideally': 2194, 'suited': 2195, 'cope': 2196, 'major': 2197, 'earlier': 2198, 'ms.': 2199, 'keys': 2200, 'barely': 2201, 'extent': 2202, 'regret': 2203, 'sofia': 2204, 'sees': 2205, 'possesses': 2206, 'raw': 2207, 'prominent': 2208, 'district': 2209, 'reluctance': 2210, 'begin': 2211, 'moods': 2212, 'board': 2213, 'metrics': 2214, 'remain': 2215, '5': 2216, 'goodies': 2217, 'bakes': 2218, 'teammates': 2219, 'rapidly': 2220, 'wherever': 2221, 'marc': 2222, 'hughes': 2223, 'achieving': 2224, 'till': 2225, 'amoy': 2226, 'customer': 2227, 'service': 2228, 'receptionist': 2229, 'clock': 2230, 'write': 2231, 'filters': 2232, 'particular': 2233, 'stays': 2234, 'returns': 2235, 'submitted': 2236, 'arithmetic': 2237, 'waves': 2238, 'toes': 2239, 'quarterback': 2240, 'opinions': 2241, 'drafting': 2242, 'partner': 2243, 'slim': 2244, 'boldness': 2245, 'limitation': 2246, 'hindrance': 2247, 'optimist': 2248, 'trait': 2249, 'innates': 2250, 'awareness': 2251, 'coached': 2252, 'opposing': 2253, 'exploit': 2254, 'buckets': 2255, 'falls': 2256, 'digits': 2257, 'offense': 2258, 'scorer': 2259, 'dictates': 2260, 'option': 2261, 'scoring': 2262, 'byers': 2263, 'appearance': 2264, 'demeanor': 2265, 'account': 2266, 'meantime': 2267, 'caylee': 2268, 'owen': 2269, 'notch': 2270, 'barrett': 2271, 'playing': 2272, 'email': 2273, 'pinch': 2274, 'minute': 2275, 'conscientious': 2276, 'diligence': 2277, 'advancing': 2278, 'introverted': 2279, 'aggressive': 2280, 'connect': 2281, 'thorough': 2282, 'internalizing': 2283, 'constituently': 2284, 'vp': 2285, 'ceo': 2286, 'beautifully': 2287, 'doyle': 2288, 'amiable': 2289, 'lance': 2290, 'hatfield': 2291, 'slowly': 2292, 'content': 2293, 'character': 2294, 'mastered': 2295, 'direct': 2296, 'reaches': 2297, 'candidate': 2298, 'unclear': 2299, 'staff': 2300, 'available': 2301, 'associates': 2302, 'gibson': 2303, 'awesome': 2304, 'tremendous': 2305, 'accuracy': 2306, 'price': 2307, 'entry': 2308, 'micheal': 2309, 'kuar': 2310, 'slip': 2311, 'cracks': 2312, 'theoretical': 2313, 'ultimately': 2314, 'struggle': 2315, 'underperforms': 2316, 'nature': 2317, 'mental': 2318, 'analyzes': 2319, 'tirelessly': 2320, 'grown': 2321, 'tremendously': 2322, 'circumstances': 2323, 'reach': 2324, 'onto': 2325, 'maintenance': 2326, 'fall': 2327, 'indicated': 2328, 'record': 2329, 'providing': 2330, 'various': 2331, 'appliances': 2332, 'adding': 2333, 'per': 2334, 'timeliness': 2335, 'persistent': 2336, 'sara': 2337, 'responsive': 2338, 'trail': 2339, 'unmotivaed': 2340, 'earning': 2341, 'compete': 2342, 'activley': 2343, 'competing': 2344, 'frustration': 2345, 'perceived': 2346, 'profile': 2347, 'accelerate': 2348, 'solidly': 2349, 'discussed': 2350, 'contributes': 2351, 'mine': 2352, 'maxed': 2353, 'welcomes': 2354, 'strives': 2355, 'fluidity': 2356, 'rigorous': 2357, 'admirable': 2358, 'looked': 2359, 'toâ‚¬\\x9dperhaps': 2360, 'driven': 2361, 'lose': 2362, 'sight': 2363, 'table': 2364, 'allowed': 2365, 'carefully': 2366, 'says': 2367, 'wastes': 2368, 'irrelevant': 2369, 'information': 2370, 'alecia': 2371, 'locating': 2372, 'towards': 2373, 'attempts': 2374, 'unsuccessful': 2375, 'priority': 2376, 'redundancy': 2377, 'list': 2378, 'considering': 2379, 'approve': 2380, 'salesman': 2381, 'study': 2382, 'records': 2383, 'lackluster': 2384, 'reasons': 2385, 'economic': 2386, 'downturn': 2387, 'system': 2388, 'conducting': 2389, 'researches': 2390, 'translate': 2391, 'profit': 2392, 'call': 2393, 'pull': 2394, 'reviewed': 2395, 'edited': 2396, 'glosses': 2397, 'repeating': 2398, 'naysayer': 2399, 'avoid': 2400, 'fashion': 2401, 'replaceable': 2402, 'regardless': 2403, 'net': 2404, 'bates': 2405, 'spends': 2406, 'overlooked': 2407, 'exceptionally': 2408, 'uncommon': 2409, 'ingenuity': 2410, 'internalizes': 2411, 'remarkable': 2412, 'kallie': 2413, 'mentorship': 2414, 'guru': 2415, 'wing': 2416, 'martin': 2417, 'extension': 2418, 'normal': 2419, 'clearly': 2420, 'embarrassment': 2421, 'cares': 2422, 'peterson': 2423, 'giving': 2424, 'score': 2425, 'semester': 2426, 'employ': 2427, 'ambitions': 2428, 'institution': 2429, 'markets.he': 2430, 'external': 2431, 'commitments': 2432, 'home': 2433, 'leaving': 2434, 'handing': 2435, 'extensions': 2436, 'redone': 2437, 'overstaying': 2438, 'lunch': 2439, 'outs': 2440, 'andrea': 2441, 'prompt': 2442, 'book': 2443, '4': 2444, 'spots': 2445, 'alone': 2446, 'ensuring': 2447, 'appreciated': 2448, 'finely': 2449, 'harrison': 2450, 'ball': 2451, 'dirty': 2452, 'doesnÃ£Â¢Ã¢â€šÂ¬Ã¢â€žÂ¢t': 2453, 'appropriate': 2454, 'restroom': 2455, 'walking': 2456, 'talk': 2457, 'distract': 2458, 'aforementioned': 2459, 'recommending': 2460, 'hourly': 2461, 'arises': 2462, 'scope[e': 2463, 'outperforms': 2464, 'rebecca': 2465, 'analytics': 2466, 'running': 2467, 'carson': 2468, 'oft': 2469, 'absent': 2470, 'viable': 2471, 'indeed': 2472, 'delegating': 2473, 'standpoint': 2474, 'argument': 2475, 'reviews': 2476, 'submitting': 2477, 'sign': 2478, 'markus': 2479, 'upgrade': 2480, 'products': 2481, 'wich': 2482, 'autority': 2483, 'decide': 2484, 'boss': 2485, 'hight': 2486, 'carroll': 2487, 'embodies': 2488, 'mission': 2489, 'discussion': 2490, 'climbing': 2491, 'loved': 2492, 'sensitive': 2493, 'fixes': 2494, 'activites': 2495, 'developmental': 2496, 'reward': 2497, 'teammate': 2498, 'sophistication': 2499, 'remaining': 2500, 'belongs': 2501, 'nowadays': 2502, 'side': 2503, 'britt': 2504, 'identify': 2505, 'slightly': 2506, 'revelation': 2507, 'makings': 2508, 'rewarded': 2509, 'play': 2510, 'function': 2511, 'smoothly': 2512, 'increasing': 2513, 'concerning': 2514, 'worried': 2515, 'keeping': 2516, 'focused': 2517, 'fortunate': 2518, 'boon': 2519, 'teagan': 2520, 'pate': 2521, 'ascend': 2522, 'gone': 2523, 'underestimated': 2524, 'came': 2525, 'picked': 2526, 'wow': 2527, 'today': 2528, 'adhere': 2529, 'treat': 2530, 'equal': 2531, 'aloof': 2532, 'blown': 2533, 'jump': 2534, 'pitched': 2535, 'wrap': 2536, 'spotted': 2537, 'contained': 2538, 'literature': 2539, 'addressed': 2540, 'demanding': 2541, 'returned': 2542, 'exacting': 2543, 'ends': 2544, 'state': 2545, 'sabotaged': 2546, 'causing': 2547, 'host': 2548, 'message': 2549, 'developer': 2550, 'impress': 2551, 'fulfill': 2552, 'obligations': 2553, 'applications': 2554, 'optimizations': 2555, 'faltered': 2556, 'christian': 2557, 'fleming': 2558, 'none': 2559, 'fly': 2560, 'analyzing': 2561, 'tracking': 2562, 'tires': 2563, 'momentum': 2564, 'inspired': 2565, 'shame': 2566, 'wishes': 2567, 'proving': 2568, 'passing': 2569, 'create': 2570, 'responsibilites': 2571, 'barnes': 2572, 'match': 2573, 'conversations': 2574, 'observe': 2575, 'creativeness': 2576, 'reflected': 2577, 'thorn': 2578, 'heights': 2579, 'esmeralda': 2580, 'read': 2581, 'resolve': 2582, 'insignificant': 2583, 'unaddressed': 2584, 'marks': 2585, 'couple': 2586, 'pleasure': 2587, 'actor': 2588, 'teacher': 2589, 'arts': 2590, 'davidson': 2591, 'nicely': 2592, 'expects': 2593, 'leo': 2594, 'crew': 2595, 'concerns': 2596, 'internalize': 2597, 'scott': 2598, 'machine': 2599, 'judgment': 2600, 'peters': 2601, 'played': 2602, 'basketball': 2603, 'guarantee': 2604, 'starter': 2605, 'shooting': 2606, 'elite': 2607, 'defenders': 2608, 'practice': 2609, 'tactics': 2610, 'nba': 2611, 'sought': 2612, 'stars': 2613, 'tomorrow': 2614, 'receiving': 2615, 'notable': 2616, 'scientific': 2617, 'astronomy': 2618, 'exciting': 2619, 'jim': 2620, 'studied': 2621, 'c': 2622, 'convinced': 2623, 'braydon': 2624, 'saddening': 2625, 'conduct': 2626, 'cason': 2627, 'perpetually': 2628, 'pass': 2629, 'checkpoint': 2630, 'necessity': 2631, 'replacement': 2632, 'unless': 2633, 'miraculous': 2634, 'lawson': 2635, 'genuine': 2636, 'countless': 2637, 'brought': 2638, 'corporate': 2639, 'nice': 2640, 'ver': 2641, 'risky': 2642, 'saw': 2643, 'positivity': 2644, 'rally': 2645, 'common': 2646, 'remained': 2647, 'sub': 2648, 'foreseeable': 2649, 'ellis': 2650, 'delaying': 2651, 'games': 2652, 'adeptly': 2653, 'churns': 2654, 'practical': 2655, 'oftentimes': 2656, 'dirt': 2657, 'behaviors': 2658, 'proficiency': 2659, 'median': 2660, 'amongst': 2661, 'domain': 2662, 'response': 2663, '12': 2664, 'extraordinarily': 2665, 'faults': 2666, 'noel': 2667, 'chapman': 2668, 'reflect': 2669, 'spending': 2670, 'broderick': 2671, 'ordinary': 2672, 'therefore': 2673, 'test': 2674, 'miss': 2675, 'archie': 2676, 'considerable': 2677, 'initiatives': 2678, 'documenting': 2679, 'workflows': 2680, 'base': 2681, 'competency': 2682, 'migration': 2683, 'handled': 2684, 'upcoming': 2685, 'certification': 2686, 'boost': 2687, 'layla': 2688, 'representative': 2689, 'responsible': 2690, 'handling': 2691, 'answered': 2692, 'attended': 2693, 'tickets': 2694, 'database': 2695, 'trainer': 2696, 'students': 2697, 'picking': 2698, 'appears': 2699, 'appear': 2700, 'rank': 2701, 'carry': 2702, 'amply': 2703, 'wanting': 2704, 'dismal': 2705, 'practically': 2706, 'existent': 2707, 'earn': 2708, 'jackson': 2709, 'beneficial': 2710, 'reflective': 2711, 'diverse': 2712, '50': 2713, 'achievement': 2714, 'prior': 2715, 'permanent': 2716, 'consecutive': 2717, 'outline': 2718, 'item': 2719, 'headed': 2720, 'gifted': 2721, 'endeavors': 2722, 'plays': 2723, 'actors': 2724, 'whitfield': 2725, 'delivery': 2726, 'satisfying': 2727, 'jaiden': 2728, 'failing': 2729, 'lacklustre': 2730, '1': 2731, 'elsewhere': 2732, 'aniya': 2733, '....': 2734, 'truthfully': 2735, 'applaud': 2736, 'accurately': 2737, 'enhance': 2738, 'engaged': 2739, 'untill': 2740, 'continually': 2741, 'reccomend': 2742, 'terminate': 2743, 'talks': 2744, 'modest': 2745, 'surpass': 2746, 'kidd': 2747, 'thing': 2748, 'older': 2749, 'pushed': 2750, 'undergo': 2751, 'inorder': 2752, 'sporadic': 2753, 'bursts': 2754, 'bogged': 2755, 'distractions': 2756, 'leverage': 2757, 'mindfulness': 2758, 'cost': 2759, 'businesses': 2760, 'alike': 2761, 'supports': 2762, 'houghtan': 2763, 'influential': 2764, 'fill': 2765, 'shoes': 2766, 'prevent': 2767, 'jobless': 2768, 'slipping': 2769, 'issued': 2770, 'reserved': 2771, 'accordance': 2772, 'resulted': 2773, 'rework': 2774, 'created': 2775, 'toxic': 2776, 'concluded': 2777, 'okay': 2778, 'surprised': 2779, 'mediocre': 2780, 'text': 2781, 'messages': 2782, 'notes': 2783, 'incomplete': 2784, 'secretary': 2785, 'unacceptable': 2786, 'impressing': 2787, 'poractive': 2788, 'colloborative': 2789, 'variations': 2790, 'rule': 2791, 'innovatively': 2792, 'upper': 2793, 'ethics': 2794, 'learned': 2795, 'merely': 2796, 'passable': 2797, 'demeanour': 2798, 'matched': 2799, 'overarching': 2800, 'listener': 2801, 'teamworkÃ¢â‚¬': 2802, 'â„¢': 2803, 'murphy': 2804, 'whatsoever': 2805, 'ben': 2806, 'ought': 2807, 'pro': 2808, 'questionable': 2809, 'chatting': 2810, 'serves': 2811, 'distraction': 2812, 'decreases': 2813, 'behave': 2814, 'maturely': 2815, 'mindful': 2816, 'hesitate': 2817, 'adaptability': 2818, 'procrastination': 2819, 'committing': 2820, 'drag': 2821, 'socializing': 2822, 'adequately': 2823, 'equipped': 2824, 'paralegal': 2825, 'distinguishable': 2826, 'instance': 2827, 'templates': 2828, 'fixed': 2829, 'force': 2830, 'seldom': 2831, 'white': 2832, 'deegan': 2833, 'mostly': 2834, 'hindered': 2835, 'explanation': 2836, 'depending': 2837, 'pattern': 2838, 'assume': 2839, 'skirts': 2840, 'relies': 2841, 'portions': 2842, 'paragraph': 2843, 'plagiarized': 2844, 'anticipated': 2845, 'combative': 2846, 'coachable': 2847, 'scattered': 2848, 'smashing': 2849, 'latest': 2850, 'include': 2851, 'shore': 2852, 'deficiencies': 2853, 'workspace': 2854, 'upbeat': 2855, 'margin': 2856, 'profits': 2857, 'collaborative': 2858, 'grades': 2859, 'diploma': 2860, 'academic': 2861, 'law': 2862, 'automated': 2863, 'status': 2864, 'store': 2865, 'prem': 2866, 'cloud': 2867, 'network': 2868, 'trigger': 2869, 'stakeholders': 2870, 'saved': 2871, '30000': 2872, 'usd': 2873, 'web': 2874, 'programming': 2875, 'combined': 2876, 'unstoppable': 2877, 'hays': 2878, 'unresolved': 2879, '\\t ': 2880, 'perspective': 2881, 'delays': 2882, 'deliverables': 2883, 'instead': 2884, 'hosting': 2885, 'augment': 2886, 'retain': 2887, 'cook': 2888, 'queue': 2889, 'agreement': 2890, 'interact': 2891, 'glowing': 2892, 'fear': 2893, 'jest': 2894, 'unparalleled': 2895, 'infectious': 2896, 'covering': 2897, 'topics': 2898, 'analyzed': 2899, 'tiny': 2900, 'noticeable': 2901, 'missing': 2902, 'periods': 2903, 'spaces': 2904, 'submission': 2905, 'four': 2906, 'avail': 2907, 'spirit': 2908, 'witted': 2909, 'miles': 2910, 'raving': 2911, 'reliably': 2912, 'accepting': 2913, 'affected': 2914, 'placement': 2915, 'nevertheless': 2916, 'competence': 2917, 'outweighs': 2918, 'cases': 2919, 'joyce': 2920, 'tis': 2921, 'evaluate': 2922, 'priorities': 2923, 'interesting': 2924, 'isn;t': 2925, 'bearings': 2926, 'misunderstood': 2927, 'purchased': 2928, 'fifty': 2929, 'compare': 2930, 'hiring': 2931, 'placed': 2932, 'noting': 2933, 'recheck': 2934, 'doubles': 2935, 'stuck': 2936, 'tell': 2937, 'scenario': 2938, 'scratch': 2939, 'lightly': 2940, 'offish': 2941, 'submissions': 2942, 'decreasing': 2943, 'judgments': 2944, 'failure': 2945, 'potentialities': 2946, 'slumped': 2947, 'diminished': 2948, 'resist': 2949, 'assurance': 2950, 'vargas': 2951, 'user': 2952, 'interface': 2953, 'operated': 2954, 'types': 2955, 'website': 2956, 'mobile': 2957, 'machines': 2958, 'concerned': 2959, 'heavily': 2960, 'portfolios': 2961, 'negotiator': 2962, 'fearless': 2963, 'correcting': 2964, 'ambitious': 2965, 'allocated': 2966, 'engagement': 2967, 'retaining': 2968, 'extract': 2969, 'executing': 2970, 'beard': 2971, 'watch': 2972, 'fans': 2973, 'journey': 2974, 'hipos': 2975, 'pipeline': 2976, 'softening': 2977, 'mentoring': 2978, 'tap': 2979, 'promote': 2980, 'pragmatic': 2981, 'underachiever': 2982, 'lucky': 2983, 'calling': 2984, 'shifts': 2985, 'waitress': 2986, 'refuses': 2987, 'approaches': 2988, 'counterargument': 2989, 'gracious': 2990, 'overseeing': 2991, 'interns': 2992, 'attends': 2993, 'withint': 2994, 'gun': 2995, 'fraction': 2996, 'jennings': 2997, 'loosing': 2998, 'criterias': 2999, 'liable': 3000, 'impact': 3001, 'miller': 3002, 'dwarfed': 3003, 'obvious': 3004, 'recover': 3005, 'persistence': 3006, 'wholly': 3007, 'whilst': 3008, 'contemporaries': 3009, 'commended': 3010, 'unlock': 3011, 'nobody': 3012, 'section': 3013, 'standing': 3014, 'reminded': 3015, 'organzination': 3016, 'talia': 3017, 'shines': 3018, 'surreal': 3019, 'sat': 3020, 'chair': 3021, 'trials': 3022, 'jury': 3023, 'verdicts': 3024, 'politics': 3025, 'shareholder': 3026, 'camden': 3027, 'county': 3028, 'rumored': 3029, 'senate': 3030, '6th': 3031, 'legislative': 3032, 'thaddeus': 3033, '80': 3034, 'weaknesses': 3035, 'multiply': 3036, 'strength': 3037, 'vital': 3038, 'hierarchy': 3039, 'unpaid': 3040, 'ten': 3041, 'sense': 3042, 'intuition': 3043, 'rock': 3044, 'middling': 3045, 'body': 3046, 'somewhere': 3047, 'proof': 3048, 'link': 3049, 'aims': 3050, 'hardest': 3051, 'enterprise': 3052, 'tailors': 3053, 'humble': 3054, 'incorporating': 3055, 'disappoint': 3056, 'rehire': 3057, 'workdays': 3058, 'property': 3059, 'maximize': 3060, 'carried': 3061, 'raised': 3062, 'realise': 3063, 'expressly': 3064, 'formal': 3065, 'add': 3066, 'existing': 3067, 'uncertain': 3068, 'regarding': 3069, 'parker': 3070, 'spent': 3071, 'pursuing': 3072, 'application': 3073, 'suggests': 3074, 'reprimands': 3075, 'opinion': 3076, 'hunt': 3077, 'credit': 3078, 'flourish': 3079, 'incorporate': 3080, 'ship': 3081, 'guide': 3082, 'greatness': 3083, 'scene': 3084, 'slips': 3085, 'sets': 3086, 'apart': 3087, 'arrives': 3088, 'neglects': 3089, 'expressed': 3090, 'dissatisfaction': 3091, 'grasping': 3092, 'projects-': 3093, 'rush': 3094, 'reduces': 3095, 'though-': 3096, 'goofing': 3097, 'intentions': 3098, 'trys': 3099, 'scores': 3100, 'clayton': 3101, 'everybody': 3102, 'surely': 3103, 'season': 3104, 'uplifting': 3105, \"''\": 3106, 'kinetic': 3107, 'physical': 3108, 'maybe': 3109, 'displayed': 3110, 'happen': 3111, 'collaboration': 3112, 'bone': 3113, 'characterized': 3114, 'unusual': 3115, 'standout': 3116, 'overpromised': 3117, 'squeaks': 3118, 'accomplishment': 3119, 'engine': 3120, 'strategical': 3121, 'pushes': 3122, 'lacked': 3123, 'pages': 3124, 'footnotes': 3125, 'numbering': 3126, 'scramble': 3127, 'realizing': 3128, 'attributed': 3129, 'strides': 3130, 'boot': 3131, 'camp': 3132, 'expanded': 3133, 'culmination': 3134, 'decades': 3135, 'faced': 3136, 'tribulations': 3137, 'folded': 3138, 'distress': 3139, 'hunter': 3140, 'oscillates': 3141, 'competently': 3142, 'brief': 3143, 'transmittal': 3144, 'letters': 3145, 'unexceptional': 3146, 'compiling': 3147, 'laziest': 3148, 'displeasure': 3149, 'lies': 3150, 'stamp': 3151, 'texts': 3152, 'peoples': 3153, 'backs': 3154, 'blink': 3155, 'removal': 3156, 'west': 3157, 'geroge': 3158, 'fellow': 3159, 'devotion': 3160, 'secondly': 3161, 'mindset': 3162, 'recorded': 3163, '632': 3164, 'workhorse': 3165, 'trial': 3166, 'marked': 3167, 'workaday': 3168, 'quarters': 3169, 'sum': 3170, 'albeit': 3171, 'general': 3172, 'view': 3173, 'carr': 3174, 'sells': 3175, 'fruitful': 3176, 'patience': 3177, 'gotten': 3178, 'length': 3179, 'wanted': 3180, 'zoned': 3181, 'naturally': 3182, 'bubbly': 3183, 'horne': 3184, 'lagging': 3185, 'occasional': 3186, 'sixth': 3187, 'services': 3188, 'coordinator': 3189, 'explained': 3190, 'involvement': 3191, 'terell': 3192, 'introductory': 3193, 'requiring': 3194, 'agility': 3195, 'shies': 3196, 'preference': 3197, 'shot': 3198, 'including': 3199, 'referrals': 3200, 'drawback': 3201, 'tendency': 3202, 'exploring': 3203, 'alternative': 3204, 'courses': 3205, 'risen': 3206, 'unmotivated': 3207, 'probation': 3208, 'suspicious': 3209, 'substance': 3210, 'abuse': 3211, 'rolled': 3212, 'bed': 3213, 'locks': 3214, 'door': 3215, 'surfaces': 3216, 'except': 3217, 'refill': 3218, 'cup': 3219, 'erratic': 3220, 'security': 3221, 'card': 3222, '18': 3223, 'weekend': 3224, 'presumably': 3225, 'drug': 3226, 'polite': 3227, 'rounds': 3228, 'super': 3229, 'streamlines': 3230, 'brainstorming': 3231, 'wildcard': 3232, 'crass': 3233, 'recently': 3234, 'implementing': 3235, 'stanley': 3236, '3rd': 3237, 'dress': 3238, 'code': 3239, 'hostile': 3240, 'fired': 3241, 'justice': 3242, 'dark': 3243, 'horse': 3244, 'overtime': 3245, 'volunteering': 3246, 'coverage': 3247, 'bored': 3248, 'intellectually': 3249, 'smartest': 3250, 'contains': 3251, 'speaks': 3252, 'entrust': 3253, 'grand': 3254, 'hopes': 3255, 'embrace': 3256, 'storm': 3257, 'disappointment': 3258, 'course': 3259, 'updates': 3260, 'ignored': 3261, 'largely': 3262, 'edits': 3263, 'suggested': 3264, 'scholarship': 3265, 'brilliant': 3266, 'engineer': 3267, 'university': 3268, 'corridors': 3269, 'assets': 3270, 'evans': 3271, 'progressing': 3272, 'feet': 3273, 'ground': 3274, 'locations': 3275, 'wokrkini': 3276, 'neesds': 3277, 'ot': 3278, 'wokr': 3279, 'center': 3280, 'sake': 3281, 'blazes': 3282, 'flip': 3283, 'prescribed': 3284, 'rodriquez': 3285, 'satisfaction': 3286, 'predict': 3287, 'cutting': 3288, 'edge': 3289, 'prospects': 3290, 'prepare': 3291, 'casework': 3292, 'nearly': 3293, 'vacation': 3294, 'investigative': 3295, 'glitches': 3296, 'assess': 3297, 'esmealda': 3298, 'nine': 3299, 'fiver': 3300, 'detriment': 3301, 'russell': 3302, 'pleasantly': 3303, 'glued': 3304, 'getter': 3305, 'juggling': 3306, 'donovan': 3307, 'avoiding': 3308, 'cited': 3309, 'trudge': 3310, 'hires': 3311, 'remarkably': 3312, 'confusing': 3313, 'outlier': 3314, 'wondering': 3315, 'moved': 3316, 'deals': 3317, 'charts': 3318, 'using': 3319, 'objective': 3320, 'language': 3321, 'session': 3322, 'therapy': 3323, 'kids': 3324, 'children': 3325, 'multi': 3326, 'tasking': 3327, 'protocols': 3328, 'displaying': 3329, 'moves': 3330, 'ross': 3331, 'grasp': 3332, 'settled': 3333, 'superior': 3334, 'pieces': 3335, 'wandering': 3336, 'chat': 3337, 'inability': 3338, 'praised': 3339, 'puzzle': 3340, 'uphold': 3341, 'actual': 3342, 'implementation': 3343, 'reminders': 3344, 'qualified': 3345, 'resumes': 3346, 'welcome': 3347, 'component': 3348, 'luster': 3349, 'accomplished': 3350, 'attempted': 3351, 'advanced': 3352, 'frank': 3353, 'deteriorated': 3354, 'subjects': 3355, 'attempt': 3356, 'strongest': 3357, 'teamplayer': 3358, 'listened': 3359, 'cooperated': 3360, 'water': 3361, '11': 3362, '13': 3363, 'motions': 3364, 'summary': 3365, 'included': 3366, 'motion': 3367, 'lone': 3368, 'wolf': 3369, 'preferring': 3370, 'dispassionate': 3371, 'partnership': 3372, 'rounded': 3373, 'punctuality': 3374, 'burden': 3375, 'timeframe': 3376, 'reading': 3377, 'fourth': 3378, 'eighth': 3379, 'markups': 3380, 'thoughtful': 3381, 'crushing': 3382, 'express': 3383, 'appreciation': 3384, 'honor': 3385, 'flash': 3386, 'applied': 3387, 'lengthy': 3388, 'shoddy': 3389, 'lenient': 3390, 'informing': 3391, 'supposed': 3392, 'sorry': 3393, 'firing': 3394, 'jimmy': 3395, 'synthesize': 3396, 'writer': 3397, 'workshop': 3398, 'skilful': 3399, 'fan': 3400, 'effectively': 3401, 'documented': 3402, 'documentation': 3403, 'via': 3404, 'speeches': 3405, 'satisfactorily': 3406, 'respects': 3407, 'stepping': 3408, 'welcomed': 3409, 'join': 3410, 'managers': 3411, 'remind': 3412, 'remembers': 3413, 'reminding': 3414, 'reported': 3415, 'overwhelmed': 3416, 'stressed': 3417, 'simplest': 3418, 'whiz': 3419, 'halting': 3420, 'adjusted': 3421, 'fitting': 3422, 'stride': 3423, 'immensely': 3424, 'hi': 3425, 'artist': 3426, 'sings': 3427, 'dances': 3428, 'art': 3429, 'acting': 3430, 'tv': 3431, 'series': 3432, 'footing': 3433, 'containing': 3434, 'memory': 3435, 'stuff': 3436, 'effectiveness': 3437, 'believed': 3438, 'perfomance': 3439, 'accounting': 3440, 'apologized': 3441, 'tax': 3442, 'prone': 3443, 'tension': 3444, 'redeeming': 3445, 'negatives': 3446, 'outweigh': 3447, 'gaining': 3448, 'inconsistently': 3449, 'acquirring': 3450, 'sufficient': 3451, 'maximized': 3452, 'morning': 3453, 'gay': 3454, 'bread': 3455, 'butter': 3456, 'stream': 3457, 'noted': 3458, 'increases': 3459, 'relates': 3460, 'eligibility': 3461, 'percentage': 3462, 'shadowing': 3463, 'bill': 3464, 'fry': 3465, 'engineering': 3466, 'insight': 3467, 'deployment': 3468, 'configuration': 3469, 'ii': 3470, 'hahn': 3471, 'believ': 3472, 'aboard': 3473, 'traits': 3474, 'upward': 3475, 'mobility': 3476, 'hamilton': 3477, 'avoided': 3478, 'identifying': 3479, 'strategic': 3480, 'versus': 3481, 'operational': 3482, 'dawson': 3483, 'jeopardizes': 3484, 'scrambling': 3485, 'boundaries': 3486, 'anticipate': 3487, 'charting': 3488, 'looks': 3489, 'critically': 3490, 'streaky': 3491, 'fanbase': 3492, 'carrying': 3493, 'wildly': 3494, 'mlb': 3495, 'upside': 3496, 'caliber': 3497, 'analyst': 3498, 'ample': 3499, 'warning': 3500, 'respectable': 3501, 'strongly': 3502, 'contract': 3503, 'deon': 3504, 'temporary': 3505, 'education': 3506, 'unprepared': 3507, 'refer': 3508, 'exceptions': 3509, 'depended': 3510, 'complicated': 3511, 'money': 3512, \"'em\": 3513, 'undertaking': 3514, 'awarded': 3515, 'employed': 3516, 'intern': 3517, 'resisted': 3518, 'form': 3519, 'superiors': 3520, 'human': 3521, 'similar': 3522, 'allotted': 3523, 'marketing': 3524, 'appealing': 3525, 'audience': 3526, 'collaborate': 3527, 'taker': 3528, 'initiates': 3529, 'waits': 3530, 'commendable': 3531, 'sullivan': 3532, 'reckoned': 3533, 'bottlenecks': 3534, 'flow': 3535, 'flexible': 3536, 'hey': 3537, 'nathan': 3538, 'dead': 3539, 'weight': 3540, 'midnight': 3541, 'nighter': 3542, 'among': 3543, 'bar': 3544, 'weeds': 3545, 'landing': 3546, 'pm': 3547, 'exponential': 3548, 'women': 3549, 'plain': 3550, 'morale': 3551, 'transition': 3552, 'educator': 3553, 'complies': 3554, 'blow': 3555, 'plow': 3556, 'anymore': 3557, 'flashed': 3558, 'settle': 3559, 'negatively': 3560, 'affects': 3561, 'risks': 3562, 'six': 3563, 'undertaken': 3564, 'fruition': 3565, 'acquired': 3566, 'hints': 3567, 'redeemable': 3568, 'exerted': 3569, 'hardwork': 3570, 'resourceful': 3571, 'fundamental': 3572, 'resulting': 3573, 'attentiveness': 3574, 'inching': 3575, 'latter': 3576, 'gem': 3577, 'lloyd': 3578, 'systems': 3579, 'march': 3580, 'modere': 3581, 'foundational': 3582, 'built': 3583, 'favourite': 3584, 'managerial': 3585, 'lunches': 3586, 'dressed': 3587, 'accordingly': 3588, 'happened': 3589, '15': 3590, '+': 3591, 'sticks': 3592, 'shooter': 3593, 'live': 3594, 'timed': 3595, '---': 3596, 'generous': 3597, 'trained': 3598, 'hesitance': 3599, 'incremental': 3600, 'promotions': 3601, 'doubtful': 3602, 'intense': 3603, 'alternatives': 3604, 'posses': 3605, 'agree': 3606, 'assumptions': 3607, 'fatal': 3608, 'flaw': 3609, 'viewed': 3610, 'argumentative': 3611, 'stubborn': 3612, 'parse': 3613, 'nuances': 3614, 'materials': 3615, 'eloiseÃ£Â¢Ã¢â€šÂ¬Ã¢â€žÂ¢s': 3616, 'fulfillment': 3617, 'rebuke': 3618, 'prospect': 3619, 'desired': 3620, 'reveals': 3621, 'glimmering': 3622, 'bind': 3623, 'stretched': 3624, 'thin': 3625, 'concentrates': 3626, 'zero': 3627, 'coordination': 3628, 'slacked': 3629, 'coupling': 3630, 'billy': 3631, 'appraisal': 3632, 'decision': 3633, 'classic': 3634, 'aligned': 3635, 'garner': 3636, 'fields': 3637, 'hampering': 3638, 'correlate': 3639, 'formulas': 3640, 'incorrectly': 3641, 'nails': 3642, 'ensures': 3643, 'masters': 3644, 'decline': 3645, 'analyze': 3646, 'heidi': 3647, 'habits': 3648, 'generating': 3649, 'participates': 3650, 'betterment': 3651, 'prefectisium': 3652, 'optimistic': 3653, 'zachary': 3654, 'delegate': 3655, 'assistant': 3656, '230': 3657, 'kpm': 3658, 'efficency': 3659, 'juniors': 3660, 'seeking': 3661, '65': 3662, 'timid': 3663, 'reducing': 3664, 'transaction': 3665, 'name': 3666, 'literally': 3667, 'nad': 3668, 'sentiments': 3669, 'suffer': 3670, 'commit': 3671, 'volunteered': 3672, 'needing': 3673, 'scales': 3674, 'unnecessary': 3675, 'bites': 3676, 'reasonably': 3677, 'chew': 3678, 'dropping': 3679, 'hazard': 3680, 'hate': 3681, 'endless': 3682, 'valid': 3683, 'notification': 3684, 'underwhelming': 3685, 'emphasis': 3686, '.but': 3687, 'sectors': 3688, 'gradual': 3689, 'williams': 3690, 'dixon': 3691, 'fewer': 3692, 'round': 3693, 'loyal': 3694, 'junior': 3695, 'revisit': 3696, 'liaised': 3697, 'unknown': 3698, 'arguably': 3699, 'wider': 3700, 'implied': 3701, 'beyong': 3702, 'specification': 3703, 'strikingly': 3704, 'accepted': 3705, 'recognize': 3706, 'implore': 3707, 'invigorate': 3708, 'aspirations': 3709, 'integral': 3710, 'dutiful': 3711, 'stretches': 3712, 'happens': 3713, 'charming': 3714, 'station': 3715, 'meanwhile': 3716, 'slacks': 3717, 'passed': 3718, 'ha': 3719, 'font': 3720, 'randomly': 3721, 'spacing': 3722, 'importance': 3723, 'invested': 3724, 'econometrics': 3725, 'steadily': 3726, 'positively': 3727, 'reputation': 3728, 'discover': 3729, 'null': 3730, 'joining': 3731, 'terminated': 3732, 'preform': 3733, 'functions': 3734, 'paperwork': 3735, 'counterarguments': 3736, 'plug': 3737, 'hole': 3738, 'perspectives': 3739, 'source': 3740, 'footnoted': 3741, 'citations': 3742, 'considered': 3743, 'deep': 3744, 'ethnic': 3745, 'phones': 3746, 'daydreaming': 3747, 'deficient': 3748, 'document': 3749, 'observed': 3750, 'regan': 3751, 'rhodes': 3752, 'exeptional': 3753, 'deeper': 3754, 'cognizant': 3755, 'corrects': 3756, 'ordeals': 3757, 'disability': 3758, 'gained': 3759, 'outwork': 3760, 'outlast': 3761, 'faster': 3762, 'diamond': 3763, 'rough': 3764, 'tutelage': 3765, 'selected': 3766, 'implemented': 3767, 'adopted': 3768, 'wide': 3769, 'trusty': 3770, 'recognized': 3771, 'mathews': 3772, 'progresses': 3773, 'friendlier': 3774, 'layers': 3775, 'sooner': 3776, 'world': 3777, 'inattention': 3778, 'costly': 3779, 'boy': 3780, 'fulfills': 3781, 'depends': 3782, 'batch': 3783, 'disregarded': 3784, 'third': 3785, 'stricter': 3786, 'terrell': 3787, 'cultivate': 3788, 'facets': 3789, 'factors': 3790, 'limiting': 3791, 'graciously': 3792, 'therefor': 3793, 'commend': 3794, 'grace': 3795, '<UNK>': 1}\n",
      "LEXICON SAMPLE (3795 total items):\n",
      "{'jamie': 2, 'delivered': 3, 'fantastic': 4, 'results': 5, '.': 6, 'work': 7, 'submits': 8, 'regularly': 9, 'better': 10, 'colleagues': 11, ',': 12, 'continues': 13, 'seek': 14, 'feedback': 15, 'continue': 16, 'monitored': 17, 'determine': 18, 'whether': 19, 'would': 20, 'good': 21}\n"
     ]
    }
   ],
   "source": [
    "'''Count tokens (words) in texts and add them to the lexicon'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "def make_lexicon(token_seqs, min_freq, use_padding=False):\n",
    "    # First, count how often each word appears in the text. Save this count in a dictionary called token_counts\n",
    "    token_counts = {}\n",
    "    for text in token_seqs:\n",
    "      for token in text:\n",
    "        if token in token_counts:\n",
    "          token_counts[token] += 1\n",
    "        else:\n",
    "          token_counts[token] = 1\n",
    "  \n",
    "    # Then, assign each word to a numerical index, i.e save  all these words in a list. Filter words that occur less than or equal to min_freq times.\n",
    "    \n",
    "    lexicon = [token for token, _ in token_counts.items() if token_counts[token] >= min_freq]\n",
    "    \n",
    "    #create a dictionary lexicon that maps each word to its index. Note that indexes will start from 2,  index 0 is saved for padding and index 1 for unknown words ('<UNK>')\n",
    "    lexicon = {token:index+2 for index, token in enumerate(lexicon)}\n",
    "    \n",
    "    lexicon[u'<UNK>'] = 1 # Unknown words are those that occur fewer than min_freq times\n",
    "    lexicon_size = len(lexicon)\n",
    "    print(lexicon)\n",
    "\n",
    "    print(\"LEXICON SAMPLE ({} total items):\".format(lexicon_size))\n",
    "    print(dict(list(lexicon.items())[:20]))\n",
    "    \n",
    "    return lexicon\n",
    "\n",
    "lexicon = make_lexicon(token_seqs=train_reviews['Tokenized_Review'], min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3795"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "6ClxwJxazi0-",
    "outputId": "8790a2ef-7cb9-4ad0-9fe6-4a40935859c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized_Review</th>\n",
       "      <th>Review_Idxs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jamie, delivered, fantastic, results, ., work...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[jude, potential, needs, coaching, several, ar...</td>\n",
       "      <td>[36, 37, 38, 39, 40, 41, 6, 42, 7, 43, 33, 44,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[alonso, outstanding, team, member, continues,...</td>\n",
       "      <td>[66, 67, 68, 69, 13, 70, 71, 6, 66, 72, 73, 74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['m, always, nervous, assigning, mackenzie, re...</td>\n",
       "      <td>[94, 95, 96, 97, 98, 99, 6, 100, 101, 102, 103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tom, show, potential, job, performance, ., to...</td>\n",
       "      <td>[135, 136, 37, 137, 138, 6, 135, 139, 140, 141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[alfie, wright, 's, work, substandard, quarter...</td>\n",
       "      <td>[153, 154, 100, 7, 155, 82, 6, 156, 84, 12, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[working, individually, ,, dean, exceeded, exp...</td>\n",
       "      <td>[181, 182, 12, 183, 184, 185, 6, 168, 12, 186,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[allan, logan, touches, anything, turns, gold,...</td>\n",
       "      <td>[205, 206, 207, 208, 209, 210, 6, 211, 212, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[yahir, harvey, ranked, category, 8, ., yahir,...</td>\n",
       "      <td>[220, 221, 222, 223, 224, 6, 220, 225, 226, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[bruno, johns, person, performs, really, great...</td>\n",
       "      <td>[234, 235, 236, 237, 126, 238, 239, 240, 241, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Tokenized_Review   \n",
       "0  [jamie, delivered, fantastic, results, ., work...  \\\n",
       "1  [jude, potential, needs, coaching, several, ar...   \n",
       "2  [alonso, outstanding, team, member, continues,...   \n",
       "3  ['m, always, nervous, assigning, mackenzie, re...   \n",
       "4  [tom, show, potential, job, performance, ., to...   \n",
       "5  [alfie, wright, 's, work, substandard, quarter...   \n",
       "6  [working, individually, ,, dean, exceeded, exp...   \n",
       "7  [allan, logan, touches, anything, turns, gold,...   \n",
       "8  [yahir, harvey, ranked, category, 8, ., yahir,...   \n",
       "9  [bruno, johns, person, performs, really, great...   \n",
       "\n",
       "                                         Review_Idxs  \n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 11, 12, 13, 14...  \n",
       "1  [36, 37, 38, 39, 40, 41, 6, 42, 7, 43, 33, 44,...  \n",
       "2  [66, 67, 68, 69, 13, 70, 71, 6, 66, 72, 73, 74...  \n",
       "3  [94, 95, 96, 97, 98, 99, 6, 100, 101, 102, 103...  \n",
       "4  [135, 136, 37, 137, 138, 6, 135, 139, 140, 141...  \n",
       "5  [153, 154, 100, 7, 155, 82, 6, 156, 84, 12, 15...  \n",
       "6  [181, 182, 12, 183, 184, 185, 6, 168, 12, 186,...  \n",
       "7  [205, 206, 207, 208, 209, 210, 6, 211, 212, 15...  \n",
       "8  [220, 221, 222, 223, 224, 6, 220, 225, 226, 22...  \n",
       "9  [234, 235, 236, 237, 126, 238, 239, 240, 241, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Convert each review from a list of tokens to a list of numbers (indices)'''\n",
    "\n",
    "def tokens_to_idxs(token_seqs, lexicon): \n",
    "    #complete this function to return a list of indexed tokens \n",
    "    idx_seqs = [[lexicon[token] if token in lexicon else lexicon['<UNK>'] for token in text] for text in token_seqs]\n",
    "    return idx_seqs\n",
    "\n",
    "train_reviews['Review_Idxs'] = tokens_to_idxs(token_seqs=train_reviews['Tokenized_Review'], lexicon=lexicon)\n",
    "                                   \n",
    "train_reviews[['Tokenized_Review', 'Review_Idxs']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "hC3TLl8tzi0_",
    "outputId": "2b287655-39a4-46d4-e0b7-8c61260c69b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN INPUT:\n",
      " [[0 0 2 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]]\n",
      "SHAPE: (878, 3796) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jamie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>limiting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>graciously</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>therefor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>commend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>grace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3796 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Count\n",
       "0                     0\n",
       "1          <UNK>      0\n",
       "2          jamie      2\n",
       "3      delivered      1\n",
       "4      fantastic      1\n",
       "...          ...    ...\n",
       "3791    limiting      0\n",
       "3792  graciously      0\n",
       "3793    therefor      0\n",
       "3794     commend      0\n",
       "3795       grace      0\n",
       "\n",
       "[3796 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Encode reviews (train_reviews['Review_Idxs']) as bag-of-words vectors'''\n",
    "\n",
    "import numpy \n",
    "\n",
    "def idx_seqs_to_bows(idx_seqs, matrix_length):\n",
    "    #complete the function to return an array having bag-of-words vectors of the encoded reviews\n",
    "    # hint: numpy.bincount()\n",
    "    bow_seqs = numpy.array([numpy.bincount(numpy.array(seq), minlength = matrix_length) \n",
    "                            for seq in idx_seqs])\n",
    "    return bow_seqs\n",
    "    \n",
    "\n",
    "bow_train_reviews = idx_seqs_to_bows(train_reviews['Review_Idxs'], \n",
    "                                     matrix_length=len(lexicon) + 1) #add one to length for padding)\n",
    "\n",
    "print(\"TRAIN INPUT:\\n\", bow_train_reviews)\n",
    "print(\"SHAPE:\", bow_train_reviews.shape, \"\\n\")\n",
    "\n",
    "#Showing an example mapping string words to counts\n",
    "lexicon_lookup = {idx: lexicon_item for lexicon_item, idx in lexicon.items()}\n",
    "lexicon_lookup[0] = \"\"\n",
    "pd.DataFrame([(lexicon_lookup[idx], count) for idx, count in enumerate(bow_train_reviews[0])], \n",
    "                 columns=['Word', 'Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWxNRWzqzi0_"
   },
   "source": [
    "##  <font color='#6629b2'>Building a Recurrent Neural Network </font>\n",
    "\n",
    "\n",
    "\n",
    "###  <font color='#6629b2'>Numerical lists to matrices</font>\n",
    "\n",
    "The input representation for the RNN explicitly encodes the order of words in the review. We'll return to the lists of the word indices contained in train_reviews['Review_Idxs']. The input to the model will be these number sequences themselves. We need to put all the reviews in the training set into a single matrix, where each row is a review and each column is a word index in that sequence. This enables the model to process multiple sequences in parallel (batches) as opposed to one at a time. Using batches significantly speeds up training. However, each review has a different number of words, so we create a padded matrix equal to the length on the longest review in the training set. For all reviews with fewer words, we prepend the row with zeros representing an empty word position. This is why the number 0 was not assigned as a word index in the lexicon. We can tell Keras to ignore these zeros during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNOyGqjPzi0_",
    "outputId": "f7e65ad0-8d6c-44aa-c887-c7b94465e404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN INPUT:\n",
      " [[   0    0    0 ...   34   35    6]\n",
      " [   0    0    0 ...   16   65    6]\n",
      " [   0    0    0 ...   92   93    6]\n",
      " ...\n",
      " [   0    0    0 ... 1486   24    6]\n",
      " [   0    0    0 ... 3067  116    6]\n",
      " [   0    0    0 ... 3795  710    6]]\n",
      "SHAPE: (878, 102) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_seq_len = max([len(seq) for seq in train_reviews['Review_Idxs']])\n",
    "def pad_idx_seqs(idx_seqs, length):\n",
    "    \n",
    "    #find the biggest review's length and save it in the variable below \n",
    "    #pad all these indexed reviews and return these padded sequences\n",
    "    #HINT: use pad_sequences function by keras\n",
    "    padded_seq = pad_sequences(sequences = idx_seqs, maxlen = length)\n",
    "    return padded_seq\n",
    "\n",
    "train_padded_idxs = pad_idx_seqs(train_reviews['Review_Idxs'],max_seq_len)\n",
    "\n",
    "print(\"TRAIN INPUT:\\n\", train_padded_idxs)\n",
    "print(\"SHAPE:\", train_padded_idxs.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentiment)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LRlr77Tzi1A"
   },
   "source": [
    "###  <font color='#6629b2'>Model Layers</font>\n",
    "The RNN will have four layers:\n",
    "\n",
    "**1. Input**: The input layer takes in the matrix of word indices.\n",
    "\n",
    "**2. Embedding**: A [layer](https://keras.io/layers/embeddings/) that converts integer word indices into distributed vector representations (embeddings), which were introduced above. The difference here is that rather than plugging in embeddings from a pretrained model as before, the word embeddings will be learned inside the model itself. Thus, the input to the model will be the word indices rather than their embeddings, and the embedding values will change as the model is trained. The mask_zero=True parameter in this layer indicates that values of 0 in the matrix (the padding) will be ignored by the model.\n",
    "\n",
    "**3. GRU**: A [recurrent (GRU) hidden layer](https://keras.io/layers/recurrent/), the central component of the model. As it observes each word in the review, it integrates the word embedding representation with what it's observed so far to compute a representation (hidden state) of the review at that timepoint. There are a few architectures for this layer - we use the GRU variation, Keras also provides LSTM or just the simple vanilla recurrent layer (see the materials at the bottom for an explanation of the difference). This layer outputs the last hidden state of the sequence (i.e. the hidden representation of the review after its last word is observed).\n",
    "\n",
    "**4. Dense**: An output [layer](https://keras.io/layers/core/#dense) that predicts the rating for the review based on its GRU representation given by the previous layer. It has one dimension that contains a continuous value (the rating). Add a proper activation function.\n",
    "\n",
    "###  <font color='#6629b2'>Parameters</font>\n",
    "\n",
    "Our function for creating the RNN takes the following parameters:\n",
    "\n",
    "**n_input_nodes**: As with the standard bag-of-words MLP, this is the number of unique words in the lexicon, plus one to account for the padding represented by 0 values. This indicates the number of rows in the embedding layer, where each row corresponds to a word.\n",
    "\n",
    "**n_embedding_nodes**: the number of dimensions (units) in the embedding layer, which can be freely defined. Here, it is set to 300.\n",
    "\n",
    "**n_hidden_nodes**: the number of dimensions in the GRU hidden layer. Like the embedding layer, this can be freely chosen. Here, it is set to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "azogBzbuzi1A"
   },
   "outputs": [],
   "source": [
    "'''Create the model'''\n",
    "# train_sentiment = pd.get_dummies(train_sentiment['nine_box_category']).values\n",
    "# train_senti_tensor = tf.convert_to_tensor(train_sentiment.values, dtype = np.int64)\n",
    "# y_train = to_categorical(y_train, 3)\n",
    "# y_test = to_categorical(y_test, 3)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def create_rnn_model(MAX_NB_WORDS, EMBEDDING_DIM, length):\n",
    "    \n",
    "    #complete this function to create a model and compile it having the 4 layers listed above.\n",
    "    #Note: Layer 1 -  Technically the shape of this layer is (batch_size, len(train_padded_idxs)).\n",
    "    # However, both the batch size and the length of the input matrix can be inferred from the input at training time. \n",
    "    # The batch size is implicitly included in the shape of the input, so it does not need to \n",
    "    # be specified as a dimension of the input. None can be given as placeholder for the input matrix length.\n",
    "    # By defining it as None, the model is flexible in accepting inputs with different lengths.\n",
    "\n",
    "    # define the model\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=length))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(500, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 20\n",
    "    batch_size = 64\n",
    "    model.summary()\n",
    "    history = model.fit(train_padded_idxs, train_sentiment, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "#     input_layer = Input(shape=(None,))\n",
    "    \n",
    "#     # Layer 2\n",
    "#     embedding_layer = Embedding(input_dim=n_input_nodes, output_dim=n_embedding_nodes, mask_zero=True)(input_layer)\n",
    "\n",
    "#     # Layer 3\n",
    "#     gru_layer = GRU(units = n_hidden_nodes)(embedding_layer)\n",
    "\n",
    "#     # Layer 4\n",
    "#     output_layer = Dense(units = 9)(gru_layer)\n",
    "\n",
    "#     #Specify which layers are input and output, compile model with loss and optimization functions\n",
    "#     model = Model(inputs=[input_layer], outputs=output_layer)\n",
    "#     model.compile(loss=\"mean_squared_error\", optimizer='adam')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "V9QquMwIzi1A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 102, 100)          200000    \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spatia  (None, 102, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 500)               1202000   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 4509      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,406,509\n",
      "Trainable params: 1,406,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_2/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Temp\\ipykernel_12796\\4194887283.py\", line 1, in <module>\n      model = create_rnn_model(2000,100,max_seq_len)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Temp\\ipykernel_12796\\1116558377.py\", line 40, in create_rnn_model\n      history = model.fit(train_padded_idxs, train_sentiment, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_2/embedding_2/embedding_lookup'\nindices[21,71] = 2078 is not in [0, 2000)\n\t [[{{node sequential_2/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_12937]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_rnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 40\u001b[0m, in \u001b[0;36mcreate_rnn_model\u001b[1;34m(MAX_NB_WORDS, EMBEDDING_DIM, length)\u001b[0m\n\u001b[0;32m     38\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m     39\u001b[0m     model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m---> 40\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_padded_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_sentiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#     input_layer = Input(shape=(None,))\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#     # Layer 2\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#     model = Model(inputs=[input_layer], outputs=output_layer)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#     model.compile(loss=\"mean_squared_error\", optimizer='adam')\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Temp\\ipykernel_12796\\4194887283.py\", line 1, in <module>\n      model = create_rnn_model(2000,100,max_seq_len)\n    File \"C:\\Users\\Urmi\\AppData\\Local\\Temp\\ipykernel_12796\\1116558377.py\", line 40, in create_rnn_model\n      history = model.fit(train_padded_idxs, train_sentiment, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Urmi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_2/embedding_2/embedding_lookup'\nindices[21,71] = 2078 is not in [0, 2000)\n\t [[{{node sequential_2/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_12937]"
     ]
    }
   ],
   "source": [
    "model = create_rnn_model(2000,100,max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4Xgy5sQzi1B"
   },
   "source": [
    "###  <font color='#6629b2'>Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSeAxBvszi1B",
    "outputId": "39eb3764-6e12-4978-def1-da6f19154eb0"
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# Train the rnn_model using the padded sequences and y=train_reviews['Rating'].\n",
    "# You need  to convert train_reviews['Rating'] to tensor before passing it as an argument\n",
    "# Hint: tf.convert_to_tensor\n",
    "# batch_size=20, epochs=5\n",
    "# '''\n",
    "# train_senti_tensor = tf.convert_to_tensor(train_sentiment.values, dtype = np.int64)\n",
    "# rnn_model.fit(x=train_padded_idxs, y=train_senti_tensor, batch_size=20, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnPG0h0izi1B"
   },
   "source": [
    "###  <font color='#6629b2'>Prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps9wqZlyzi1C",
    "outputId": "965023a6-f758-4556-cd1f-f9aa04f22fe1"
   },
   "outputs": [],
   "source": [
    "'''Put test reviews in padded matrix just how we did for train_reviews'''\n",
    "test_reviews['Tokenized_Review'] = text_to_tokens(test_reviews['feedback'])\n",
    "# lexicon_test = make_lexicon(token_seqs=test_reviews['Tokenized_Review'], min_freq=1)\n",
    "test_reviews['Review_Idxs'] = tokens_to_idxs(token_seqs=test_reviews['Tokenized_Review'], lexicon=lexicon)\n",
    "test_padded_idxs = pad_idx_seqs(test_reviews['Review_Idxs'],max_seq_len)\n",
    "\n",
    "print(\"TEST INPUT:\\n\", test_padded_idxs)\n",
    "print(\"SHAPE:\", test_padded_idxs.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwwCz7Mezi1C"
   },
   "outputs": [],
   "source": [
    "'''Predict the ratings '''\n",
    "\n",
    "#Since ratings are integers, need to round predicted rating to nearest integer\n",
    "test_reviews['RNN_Pred_Rating'] = numpy.round(model.predict(test_padded_idxs)[:,0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3XlAl5Dqq6Y",
    "outputId": "8d38c540-395c-4ca6-cbf4-656210f8b8d0"
   },
   "outputs": [],
   "source": [
    "test_reviews\n",
    "import sklearn\n",
    "accr = model.evaluate(test_padded_idxs,test_sentiment)\n",
    "# score = sklearn.metrics.accuracy_score(y_true = test_sentiment, y_pred = test_reviews['RNN_Pred_Rating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ADkB8eozi1C"
   },
   "source": [
    "###  <font color='#6629b2'>Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZmfLkFWzi1C",
    "outputId": "763f3bd1-d4fc-4acd-fe89-6325a555a0e4"
   },
   "outputs": [],
   "source": [
    "# '''Evaluate the model with R^2'''\n",
    "\n",
    "# # print the r2 score\n",
    "# from sklearn.metrics import r2_score \n",
    "# final_score = r2_score(y_true = test_sentiment, y_pred = test_reviews['RNN_Pred_Rating'])\n",
    "# print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6kme50fzi1C"
   },
   "source": [
    "On the full test dataset of 25,000 reviews, the $R^2$ for this model is 0.622525. So the RNN outperforms the continuous bag-of-words MLP as well as the standard bag-of-words approach.\n",
    "Your score might not be good because we're training on only 100-200 reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UWIcQ4yzi1C"
   },
   "source": [
    "### <font color='#6629b2'>Visualizing data inside the model</font>\n",
    "\n",
    "To help visualize the data representation inside the model, we can look at the output of each layer in a model individually. Keras' Functional API lets you derive a new model with the layers from an existing model, so you can define the output to be a layer below the output layer in the original model. Calling predict() on this new model will produce the output of that layer for a given input. Of course, glancing at the numbers by themselves doesn't provide any interpretation of what the model has learned (although there are opportunities to [interpret these values](https://medium.com/civis-analytics/interpreting-and-visualizing-neural-networks-for-text-processing-e9dff0da9c22), but seeing them verifies the model is just a series of transformations from one matrix to another. The model stores its layers as the list model.layers, and you can retrieve specific layer by its position index in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RUwhDuizi1D",
    "outputId": "48f4a024-c8b7-4938-d7fd-6cb3aa4ca7f7"
   },
   "outputs": [],
   "source": [
    "'''Showing the output of the RNN embedding layer (second layer) for the test reviews'''\n",
    "\n",
    "embedding_layer = Model(inputs=rnn_model.layers[0].input, \n",
    "                        outputs=rnn_model.layers[1].output) #embedding layer is 2nd layer (index 1)\n",
    "embedding_output = embedding_layer.predict(test_padded_idxs)\n",
    "print(\"EMBEDDING LAYER OUTPUT SHAPE:\", embedding_output.shape)\n",
    "print(embedding_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbcNT3JDzi1D"
   },
   "source": [
    "## <font color='#6629b2'>Conclusion</font>\n",
    "\n",
    "As mentioned above, the models shown here could be applied to any task where the goal is to predict a score for a particular sequence. For ratings prediction, this output is ordinal, but it could also be categorical with a few simple changes to the output layer of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "DGfYtZ4Azi1D"
   },
   "source": [
    "## <font color='#6629b2'>More resources</font>\n",
    "\n",
    "Yoav Goldberg's book [Neural Network Methods for Natural Language Processing](http://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037) is a thorough introduction to neural networks for NLP tasks in general.\n",
    "\n",
    "If you'd like to learn more about what Keras is doing under the hood, there is a [Theano tutorial](http://deeplearning.net/tutorial/lstm.html) that also applies an RNN to sentiment prediction, using the same dataset here\n",
    "\n",
    "Andrej Karpathy's blog post [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) is very helpful for understanding the mathematical details of an RNN, applied to the task of language modeling. It also provides raw Python code with an implementation of the backpropagation algorithm.\n",
    "\n",
    "TensorFlow also has an RNN language model [tutorial](https://www.tensorflow.org/versions/r0.12/tutorials/recurrent/index.html) using the Penn Treebank dataset\n",
    "\n",
    "Chris Olah provides a good [explanation](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) of how LSTM RNNs work (this explanation also applies to the GRU model used here)\n",
    "\n",
    "Denny Britz's [tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) documents well both the technical details of RNNs and their implementation in Python."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Tasksentiment_rating_rnn_Urmi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
